{
  
    
        "post0": {
            "title": "How to Build a Machine Learning Model for Chemical Property Prediction",
            "content": "This notebook shows how to build a simple but strong machine-learning model for the prediction of logP (octanol-water partition coefficient). . The logP is quite an important property in medicinal and pharmaceutical chemistry, as it relates to the distribution of drugs between aqueous phases (hydrophilic phases such as blood) and other non-aqueous compartments in the human body. . The approach is tested on the recent SAMPL7 blind challenge dataset showing excellent results here. . In fact this approach can be used to predict any chemical property as long as their is enough chemical data for model building, i.e. in the form of several hundred or better thousands SMILES and property pairs. . Never use this approach for small datasets, i.e. use at least a few 100 samples if possible. That is a common mistake i.e. using the machinery of ML on small datasets without doing the due diligent statistics - paving the way for &quot;predictive&quot; models being much to over-confident, which look great in theory and academic papers but failing terribly in real-world practice! . Used libraries: . RDKit | lightgbm | pandas | scikit-learn | . Used data: . Opera curated physprop dataset(s) | SAMPL7 logP blind challenge data | . Overview &amp; individual steps . Load experimental data | Compute descriptors | Compute fingerprints | Model building | Parameter selection | Deployment &amp; Analysis | First loading all needed python libraries . from tqdm.notebook import tqdm # data science libraries import pandas as pd import lightgbm as lgb from sklearn.model_selection import KFold,cross_val_score, train_test_split, GridSearchCV from sklearn.metrics import mean_absolute_error, mean_squared_error from joblib import dump, load # cheminformatics from rdkit.Chem import AllChem as Chem from rdkit.ML.Descriptors import MoleculeDescriptors from rdkit.Chem import Descriptors from rdkit.Chem.Draw import IPythonConsole from rdkit.Chem import Draw # set some options for better visibility of DataFrames pd.set_option(&#39;display.max_rows&#39;, 500) pd.set_option(&#39;display.max_columns&#39;, 500) pd.set_option(&#39;display.width&#39;, 1000) pd.set_option(&#39;display.max_colwidth&#39;, 1000) . Loading the data . We start with loading training and test set data from SD files. Those files contain the molecular structure and the corresponding chemical property, here the logP value. The data can be found as an updated version here and the original published data here. We use a built-in library from RDKit to create a list of molecules and logP value pairs from it, in total more than 10000 samples. . Those pairs are saved in a list of dictionaries which can then be used to create a pandas DataFrame from it. This DataFrame is a very useful data structure which allows easy handling of tabular data. . For now we use only the provided training data, there is also another SD file with test data, which we leave aside completety for now and which could be used later on to finally test the results. . Lets start with downloading and unzipping the data from the source: . !wget -O ./opera_data.zip https://ndownloader.figstatic.com/files/10692997 #wget -O ./opera_data.zip https://github.com/kmansouri/OPERA/blob/master/OPERA_Data.zip?raw=true # github data !unzip ./opera_data.zip . We start with creating a DataFrame from the downloaded SD file. We ignore for now also some error message coming from parsing the molecular structures. . sd_file = &#39;./OPERA_LogP/TR_LogP_10537.sdf&#39; #sd_file = &#39;./LogP_QR.sdf&#39; # github data suppl = Chem.SDMolSupplier(sd_file) data = [] for m in tqdm(suppl): if m is None: continue smiles = Chem.MolToSmiles(m) data.append({&#39;SMILES&#39;: smiles, &#39;logP&#39;: m.GetProp(&#39;LogP&#39;)}) df = pd.DataFrame(data) df[&#39;logP&#39;] = df[&#39;logP&#39;].astype(float) # convert from string to float df . Now we have a pandas DataFrame with SMILES, encoding the molecular topology, and experimental logP values. . Computing descriptors . RDKit provides a nice tool to compute any kind of descriptors: . calculator = MoleculeDescriptors.MolecularDescriptorCalculator([x[0] for x in Descriptors._descList]) calculator.GetDescriptorNames() . Lets understand how the descriptor calculator from RDKit works. It takes a molecule and returns a tuple of all RDKit descriptors for this molecule, 200 in total. . calculator.CalcDescriptors?? . len(calculator.CalcDescriptors(Chem.MolFromSmiles(&quot;CCO&quot;))) . 200 . def smiles2desc(s): descriptors = calculator.CalcDescriptors(Chem.MolFromSmiles(s)) return descriptors . Lets first create a pandas series and then turn this (pandas) series of tuples into a pandas DataFrame containing all descriptors. This might take a while... Certainly we do not need all of those descriptors. Later we will find a way to select the descriptors we need. . We then save the DataFrame for later use and save some time during model development. By the way with the %%time command the cpu and wall times for running the code in a jupyter cell can be measured. . %%time desc_tuples = df[&#39;SMILES&#39;].apply(smiles2desc) X = pd.DataFrame(desc_tuples.tolist(), columns = calculator.GetDescriptorNames()) X . CPU times: user 1min 11s, sys: 1.4 s, total: 1min 12s Wall time: 1min 11s . MaxEStateIndex MinEStateIndex MaxAbsEStateIndex MinAbsEStateIndex qed MolWt HeavyAtomMolWt ExactMolWt NumValenceElectrons NumRadicalElectrons MaxPartialCharge MinPartialCharge MaxAbsPartialCharge MinAbsPartialCharge FpDensityMorgan1 FpDensityMorgan2 FpDensityMorgan3 BalabanJ BertzCT Chi0 Chi0n Chi0v Chi1 Chi1n Chi1v Chi2n Chi2v Chi3n Chi3v Chi4n Chi4v HallKierAlpha Ipc Kappa1 Kappa2 Kappa3 LabuteASA PEOE_VSA1 PEOE_VSA10 PEOE_VSA11 PEOE_VSA12 PEOE_VSA13 PEOE_VSA14 PEOE_VSA2 PEOE_VSA3 PEOE_VSA4 PEOE_VSA5 PEOE_VSA6 PEOE_VSA7 PEOE_VSA8 PEOE_VSA9 SMR_VSA1 SMR_VSA10 SMR_VSA2 SMR_VSA3 SMR_VSA4 SMR_VSA5 SMR_VSA6 SMR_VSA7 SMR_VSA8 SMR_VSA9 SlogP_VSA1 SlogP_VSA10 SlogP_VSA11 SlogP_VSA12 SlogP_VSA2 SlogP_VSA3 SlogP_VSA4 SlogP_VSA5 SlogP_VSA6 SlogP_VSA7 SlogP_VSA8 SlogP_VSA9 TPSA EState_VSA1 EState_VSA10 EState_VSA11 EState_VSA2 EState_VSA3 EState_VSA4 EState_VSA5 EState_VSA6 EState_VSA7 EState_VSA8 EState_VSA9 VSA_EState1 VSA_EState10 VSA_EState2 VSA_EState3 VSA_EState4 VSA_EState5 VSA_EState6 VSA_EState7 VSA_EState8 VSA_EState9 FractionCSP3 HeavyAtomCount NHOHCount NOCount NumAliphaticCarbocycles NumAliphaticHeterocycles NumAliphaticRings NumAromaticCarbocycles NumAromaticHeterocycles NumAromaticRings NumHAcceptors NumHDonors NumHeteroatoms NumRotatableBonds NumSaturatedCarbocycles NumSaturatedHeterocycles NumSaturatedRings RingCount MolLogP MolMR fr_Al_COO fr_Al_OH fr_Al_OH_noTert fr_ArN fr_Ar_COO fr_Ar_N fr_Ar_NH fr_Ar_OH fr_COO fr_COO2 fr_C_O fr_C_O_noCOO fr_C_S fr_HOCCN fr_Imine fr_NH0 fr_NH1 fr_NH2 fr_N_O fr_Ndealkylation1 fr_Ndealkylation2 fr_Nhpyrrole fr_SH fr_aldehyde fr_alkyl_carbamate fr_alkyl_halide fr_allylic_oxid fr_amide fr_amidine fr_aniline fr_aryl_methyl fr_azide fr_azo fr_barbitur fr_benzene fr_benzodiazepine fr_bicyclic fr_diazo fr_dihydropyridine fr_epoxide fr_ester fr_ether fr_furan fr_guanido fr_halogen fr_hdrzine fr_hdrzone fr_imidazole fr_imide fr_isocyan fr_isothiocyan fr_ketone fr_ketone_Topliss fr_lactam fr_lactone fr_methoxy fr_morpholine fr_nitrile fr_nitro fr_nitro_arom fr_nitro_arom_nonortho fr_nitroso fr_oxazole fr_oxime fr_para_hydroxylation fr_phenol fr_phenol_noOrthoHbond fr_phos_acid fr_phos_ester fr_piperdine fr_piperzine fr_priamide fr_prisulfonamd fr_pyridine fr_quatN fr_sulfide fr_sulfonamd fr_sulfone fr_term_acetylene fr_tetrazole fr_thiazole fr_thiocyan fr_thiophene fr_unbrch_alkane fr_urea . 0 8.000000 | 2.000000 | 8.000000 | 2.000000 | 0.360624 | 30.026 | 28.010 | 30.010565 | 12 | 0 | 0.106382 | -0.307097 | 0.307097 | 0.106382 | 1.500000 | 1.500000 | 1.500000 | 2.000000 | 2.000000 | 2.000000 | 1.115355 | 1.115355 | 1.000000 | 0.288675 | 0.288675 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | -0.33 | 2.000000e+00 | 1.670000 | 0.670000 | -5.360303 | 12.900773 | 4.794537 | 6.789076 | 0.000000 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 4.794537 | 6.789076 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 6.789076 | 4.794537 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 17.07 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 6.789076 | 0.000000 | 4.794537 | 0.000000 | 0.000000 | 8.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 2.000000 | 0.000000 | 0.000000 | 2 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | -0.1849 | 7.1210 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 16.859063 | -1.980464 | 16.859063 | 0.067556 | 0.667213 | 392.467 | 363.235 | 392.199902 | 154 | 0 | 0.189906 | -0.389712 | 0.389712 | 0.189906 | 1.321429 | 2.000000 | 2.642857 | 1.837692 | 804.748825 | 20.698306 | 16.613088 | 16.613088 | 12.963233 | 10.142335 | 10.142335 | 9.749151 | 9.749151 | 8.791253 | 8.791253 | 7.261033 | 7.261033 | -1.37 | 1.500076e+06 | 19.925309 | 5.832748 | 2.014264 | 163.871786 | 15.319582 | 12.207933 | 17.235250 | 0.000000 | 0.0 | 0.000000 | 9.589074 | 4.390415 | 0.0 | 0.0 | 25.496599 | 56.594876 | 16.747887 | 6.103966 | 29.299072 | 11.566490 | 0.0 | 0.000000 | 28.583699 | 63.828275 | 6.606882 | 23.801165 | 0.0 | 0.000000 | 0.000000 | 4.390415 | 0.000000 | 0.000000 | 50.866731 | 9.589074 | 28.583699 | 46.454498 | 23.801165 | 0.000000 | 0.000000 | 0.0 | 94.83 | 52.429697 | 24.908657 | 4.390415 | 18.121973 | 24.835569 | 0.000000 | 12.152040 | 26.847232 | 0.000000 | 0.000000 | 0.000000 | 16.859063 | 0.000000 | 24.380377 | 31.963442 | -5.169116 | -2.119134 | 0.000000 | 4.439214 | 4.479486 | 0.000000 | 0.727273 | 28 | 3 | 5 | 4 | 0 | 4 | 0 | 0 | 0 | 5 | 3 | 6 | 2 | 3 | 0 | 3 | 4 | 1.8957 | 99.9444 | 0 | 3 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 4 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 12.870043 | -1.584704 | 12.870043 | 0.041293 | 0.700523 | 404.503 | 372.247 | 404.219889 | 160 | 0 | 0.302566 | -0.457742 | 0.457742 | 0.302566 | 1.206897 | 1.931034 | 2.620690 | 1.654620 | 786.237565 | 21.189870 | 17.571026 | 17.571026 | 13.526347 | 10.837743 | 10.837743 | 10.179483 | 10.179483 | 8.916186 | 8.916186 | 7.436803 | 7.436803 | -1.53 | 2.615371e+06 | 20.731066 | 6.741324 | 2.857980 | 171.241629 | 14.949918 | 5.601051 | 12.390127 | 5.783245 | 0.0 | 5.969305 | 14.383612 | 0.000000 | 0.0 | 0.0 | 19.420579 | 67.769658 | 18.759549 | 6.103966 | 29.333529 | 17.535795 | 0.0 | 0.000000 | 28.583699 | 77.421980 | 6.606882 | 11.649125 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 46.060749 | 19.120475 | 28.583699 | 65.716963 | 11.649125 | 0.000000 | 0.000000 | 0.0 | 100.90 | 35.479440 | 24.596666 | 0.000000 | 28.951954 | 19.262465 | 31.256391 | 6.923737 | 6.076020 | 6.923737 | 6.923737 | 4.736863 | 4.885879 | 0.000000 | 35.966645 | 22.757420 | -1.358548 | -0.462239 | 0.000000 | 5.536159 | 4.924684 | 0.000000 | 0.782609 | 29 | 2 | 6 | 4 | 0 | 4 | 0 | 0 | 0 | 6 | 2 | 6 | 3 | 3 | 0 | 3 | 4 | 2.3524 | 104.6896 | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 5 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 11.975791 | -1.310347 | 11.975791 | 0.293611 | 0.736884 | 232.239 | 220.143 | 232.084792 | 88 | 0 | 0.327651 | -0.276523 | 0.327651 | 0.276523 | 1.000000 | 1.529412 | 2.000000 | 2.535973 | 461.783925 | 12.466255 | 9.318603 | 9.318603 | 8.108226 | 5.333716 | 5.333716 | 3.862281 | 3.862281 | 3.026281 | 3.026281 | 2.064079 | 2.064079 | -2.17 | 7.460405e+03 | 11.319407 | 4.008920 | 1.595456 | 98.199515 | 0.000000 | 0.000000 | 5.414990 | 11.814359 | 0.0 | 6.031115 | 20.222652 | 4.794537 | 0.0 | 0.0 | 37.255573 | 11.984273 | 0.000000 | 0.000000 | 14.383612 | 17.845474 | 0.0 | 10.633577 | 0.000000 | 18.759549 | 0.000000 | 35.895287 | 0.0 | 0.000000 | 10.633577 | 4.794537 | 0.000000 | 0.000000 | 17.845474 | 15.004065 | 0.000000 | 18.908010 | 30.331835 | 0.000000 | 0.000000 | 0.0 | 75.27 | 23.260464 | 14.383612 | 0.000000 | 0.000000 | 11.984273 | 0.000000 | 0.000000 | 37.255573 | 0.000000 | 10.633577 | 0.000000 | 0.000000 | 0.000000 | 35.006608 | 4.280408 | -0.722384 | -1.138981 | 7.959353 | 0.293611 | 1.738052 | 0.000000 | 0.250000 | 17 | 2 | 5 | 0 | 1 | 1 | 1 | 0 | 1 | 3 | 2 | 5 | 2 | 0 | 1 | 1 | 2 | 0.7004 | 60.0924 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3 | 3 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | . 4 12.770676 | -0.957338 | 12.770676 | 0.058604 | 0.410670 | 334.332 | 316.188 | 334.127720 | 128 | 0 | 0.404011 | -0.448859 | 0.448859 | 0.404011 | 1.416667 | 2.125000 | 2.750000 | 1.846855 | 756.963371 | 17.386387 | 13.289420 | 13.289420 | 11.340277 | 7.651541 | 7.651541 | 6.459246 | 6.459246 | 5.474589 | 5.474589 | 4.309835 | 4.309835 | -2.39 | 3.873907e+05 | 15.156102 | 4.577599 | 1.577721 | 137.147044 | 31.157759 | 6.606882 | 5.724986 | 11.566490 | 0.0 | 6.093240 | 9.589074 | 4.794537 | 0.0 | 0.0 | 0.000000 | 6.923737 | 30.842604 | 23.353826 | 23.857337 | 17.659730 | 0.0 | 10.216698 | 17.385241 | 24.732404 | 20.261436 | 22.540288 | 0.0 | 0.000000 | 16.784124 | 4.794537 | 0.000000 | 0.000000 | 60.629743 | 19.062800 | 5.917906 | 6.923737 | 22.540288 | 0.000000 | 0.000000 | 0.0 | 146.89 | 23.519377 | 14.383612 | 0.000000 | 41.317057 | 12.241796 | 0.000000 | 14.033535 | 0.000000 | 4.899910 | 5.316789 | 20.941061 | 10.778713 | 0.000000 | 38.432652 | 3.278157 | 10.671653 | -1.340097 | 0.109487 | -0.949597 | 1.918144 | 1.517553 | 0.533333 | 24 | 5 | 9 | 1 | 3 | 4 | 0 | 0 | 0 | 8 | 3 | 9 | 3 | 0 | 2 | 2 | 4 | -1.6512 | 80.1105 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 3 | 3 | 0 | 0 | 0 | 1 | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 2 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 10522 5.865324 | 0.743609 | 5.865324 | 0.743609 | 0.348269 | 564.691 | 559.651 | 559.625725 | 94 | 0 | 0.142392 | -0.454953 | 0.454953 | 0.142392 | 0.666667 | 1.333333 | 2.000000 | 2.372918 | 597.261908 | 13.284093 | 8.684822 | 16.614805 | 8.486071 | 4.751877 | 8.716868 | 3.350292 | 7.560638 | 2.113595 | 6.562486 | 1.263451 | 3.742155 | 0.64 | 1.073165e+04 | 15.036962 | 6.393360 | 3.392119 | 146.939781 | 4.736863 | 11.499024 | 0.000000 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 15.929944 | 94.051611 | 13.418159 | 8.945439 | 4.736863 | 79.649719 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.0 | 11.499024 | 4.736863 | 0.000000 | 11.499024 | 79.649719 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.000000 | 0.000000 | 0.0 | 9.23 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 33.862621 | 0.000000 | 0.000000 | 30.331835 | 79.649719 | 4.736863 | 10.515434 | 17.302937 | 0.000000 | 0.000000 | 0.000000 | 1.501130 | 9.597167 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 18 | 0 | 1 | 0 | 0 | 0 | 2 | 0 | 2 | 1 | 0 | 6 | 2 | 0 | 0 | 0 | 2 | 7.2914 | 91.4580 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10523 5.865324 | 0.743609 | 5.865324 | 0.743609 | 0.348269 | 564.691 | 559.651 | 559.625725 | 94 | 0 | 0.142366 | -0.454954 | 0.454954 | 0.142366 | 0.611111 | 1.222222 | 1.888889 | 2.366973 | 597.261908 | 13.284093 | 8.684822 | 16.614805 | 8.469234 | 4.745894 | 8.710885 | 3.373545 | 7.706568 | 2.088651 | 5.665565 | 1.258972 | 3.784235 | 0.64 | 1.011593e+04 | 15.036962 | 6.393360 | 3.596788 | 146.939781 | 4.736863 | 11.499024 | 0.000000 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 15.929944 | 94.051611 | 13.418159 | 8.945439 | 4.736863 | 79.649719 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.0 | 11.499024 | 4.736863 | 0.000000 | 11.499024 | 79.649719 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.000000 | 0.000000 | 0.0 | 9.23 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 33.862621 | 0.000000 | 0.000000 | 30.331835 | 79.649719 | 4.736863 | 10.544508 | 17.255529 | 0.000000 | 0.000000 | 0.000000 | 1.501130 | 9.615500 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 18 | 0 | 1 | 0 | 0 | 0 | 2 | 0 | 2 | 1 | 0 | 6 | 2 | 0 | 0 | 0 | 2 | 7.2914 | 91.4580 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10524 5.898403 | 0.737243 | 5.898403 | 0.737243 | 0.372297 | 564.691 | 559.651 | 559.625725 | 94 | 0 | 0.155400 | -0.453800 | 0.453800 | 0.155400 | 0.666667 | 1.222222 | 1.777778 | 2.399018 | 574.011908 | 13.284093 | 8.684822 | 16.614805 | 8.469234 | 4.745894 | 8.710885 | 3.375365 | 7.769727 | 2.069000 | 4.817874 | 1.294399 | 4.842952 | 0.64 | 9.689203e+03 | 15.036962 | 6.393360 | 3.596788 | 146.939781 | 4.736863 | 5.749512 | 5.749512 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 31.859888 | 78.121667 | 8.945439 | 13.418159 | 4.736863 | 79.649719 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.0 | 11.499024 | 4.736863 | 0.000000 | 11.499024 | 79.649719 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 52.695433 | 0.000000 | 0.000000 | 0.0 | 9.23 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 33.862621 | 0.000000 | 0.000000 | 30.331835 | 79.649719 | 4.736863 | 10.504760 | 17.278479 | 0.000000 | 0.000000 | 0.000000 | 1.489023 | 9.644405 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 18 | 0 | 1 | 0 | 0 | 0 | 2 | 0 | 2 | 1 | 0 | 6 | 2 | 0 | 0 | 0 | 2 | 7.2914 | 91.4580 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10525 5.949236 | 0.720484 | 5.949236 | 0.720484 | 0.301249 | 643.587 | 639.555 | 637.536237 | 100 | 0 | 0.155401 | -0.453758 | 0.453758 | 0.155401 | 0.578947 | 1.105263 | 1.684211 | 2.446755 | 617.352114 | 14.154336 | 8.985436 | 18.501415 | 8.879918 | 4.851543 | 9.609532 | 3.497360 | 8.684720 | 2.149882 | 6.249752 | 1.318948 | 5.136754 | 1.12 | 1.452390e+04 | 16.489820 | 6.919813 | 4.067050 | 160.807328 | 4.736863 | 5.749512 | 5.749512 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 15.929944 | 103.915188 | 13.418159 | 13.418159 | 4.736863 | 95.579663 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 51.101785 | 0.0 | 11.499024 | 4.736863 | 0.000000 | 11.499024 | 95.579663 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 51.101785 | 0.000000 | 0.000000 | 0.0 | 9.23 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 38.335341 | 0.000000 | 0.000000 | 24.265468 | 95.579663 | 4.736863 | 11.388169 | 20.810146 | 0.000000 | 0.000000 | 0.000000 | 1.441592 | 7.693426 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 19 | 0 | 1 | 0 | 0 | 0 | 2 | 0 | 2 | 1 | 0 | 7 | 2 | 0 | 0 | 0 | 2 | 8.0539 | 99.1580 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 6 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10526 6.159362 | 0.160160 | 6.159362 | 0.160160 | 0.339736 | 395.327 | 392.303 | 391.805444 | 100 | 0 | 0.079957 | -0.083606 | 0.083606 | 0.079957 | 0.421053 | 0.947368 | 1.578947 | 2.761979 | 663.857967 | 14.317473 | 8.877802 | 14.169305 | 8.824275 | 4.804926 | 7.450678 | 3.594060 | 6.356754 | 2.402760 | 5.189036 | 1.497827 | 3.050289 | 0.47 | 1.478826e+04 | 15.851270 | 6.071665 | 3.059058 | 144.611361 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 | 0.0 | 81.206579 | 18.199101 | 11.126903 | 35.158433 | 0.000000 | 81.206579 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 53.357534 | 0.0 | 11.126903 | 0.000000 | 0.000000 | 0.000000 | 81.206579 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 18.199101 | 35.158433 | 11.126903 | 0.0 | 0.00 | 0.000000 | 0.000000 | 0.000000 | 20.090533 | 26.194803 | 0.000000 | 6.066367 | 12.132734 | 0.000000 | 0.000000 | 81.206579 | 0.000000 | 42.050759 | 0.000000 | 1.938501 | 1.102932 | 0.000000 | 4.685586 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 19 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 2 | 0 | 0 | 7 | 1 | 0 | 0 | 0 | 2 | 7.9274 | 86.9480 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10527 rows × 200 columns . X.to_csv(&#39;tmp.csv&#39;,index=False) . Computing circular fingerprints as descriptors . This step is optional - you can also directly proceed to the model training. For comparison lets also use Morgan fingerprints /ECFP as descriptors. There is some nice overview on different fingerprints also in this presentation. . Here also RDKit provides some nice function for fingerprint generation, lets understand how they work: . Chem.GetMorganFingerprintAsBitVect?? n_bits = 2048 fp = Chem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(&quot;CCO&quot;),2,nBits=n_bits) . def smiles2fingerprints(s): fp = Chem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(s),2,nBits=n_bits) return [int(x) for x in fp.ToBitString()] . %%time fp_tuples = df[&#39;SMILES&#39;].apply(smiles2fingerprints) . CPU times: user 3.97 s, sys: 56 ms, total: 4.03 s Wall time: 4.02 s . fp_names = [&#39;fp&#39;+str(i) for i in range(n_bits)] X_fp = pd.DataFrame(fp_tuples.tolist(), columns = fp_names) X_fp.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10527 entries, 0 to 10526 Columns: 2048 entries, fp0 to fp2047 dtypes: int64(2048) memory usage: 164.5 MB . X_fp.to_csv(&#39;tmp_fp.csv&#39;,index=False) . In case we want to use fingerprints instead as descriptors, just load the tmp_fp.csv dataframe now instead of the tmp.csv. . X = pd.read_csv(&#39;tmp.csv&#39;) X.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10527 entries, 0 to 10526 Columns: 200 entries, MaxEStateIndex to fr_urea dtypes: float64(96), int64(104) memory usage: 16.1 MB . y = df.logP . Check if we have still the correct dimensions for the train data and the target data. . assert(X.shape[0]==len(y)) . Model training . Lets prepare the training. We are using the lightgbm library, which uses stochastic gradient boosting for model building, which is currently the most effective way to train tabular data like this. There are several libraries for this, another quite commonly used library is XGBoost. . There are a lot of parameters to tune. We only use the most important ones. You can find more info on the parameters to choose on the LightGBM homepage. . We use an 80/20 split for train and validation set. The validation is kept aside and with the training set we perform a 5-fold cross-validation. . lgb_params = {&#39;num_leaves&#39;: 128, &#39;min_child_samples&#39;: 79, &#39;objective&#39;: &#39;regression&#39;, &#39;max_depth&#39;: 15, &#39;learning_rate&#39;: 0.01, &quot;boosting_type&quot;: &quot;gbdt&quot;, &quot;subsample_freq&quot;: 1, &quot;subsample&quot;: 0.5, &quot;bagging_seed&quot;: 11, &quot;metric&quot;: &#39;mae&#39;, &quot;verbosity&quot;: -1, &#39;reg_alpha&#39;: 0.1, &#39;reg_lambda&#39;: 0.3, &#39;colsample_bytree&#39;: 1.0, &#39;n_estimators&#39;: 4000, &#39;n_jobs&#39;: -1, } model = lgb.LGBMRegressor(**lgb_params) cv = KFold(n_splits=5, shuffle=True, random_state=42) Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True) print(Xtrain.shape) print(Xval.shape) . (8421, 200) (2106, 200) . Now we actually fit the model, this also may take a while. You can adjust the n_jobs parameter to improve performance. You may also change the verbosity parameter in order to get more feedback during the calculation. . Lets also remove some of the features. We do this by looking at the feature importance. There are more advanced methods for feature selection but for the sake of brevity we just use this. For simplicity we also use the API of lightgbm itself. . model.fit(Xtrain, ytrain, early_stopping_rounds=100,eval_metric=[&#39;l1&#39;], eval_set=[(Xtrain, ytrain), (Xval, yval)]) . lgb.plot_importance(model, max_num_features=40, figsize=(15,15)) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f1f6d5948b0&gt; . Not as a suprise, the predicted logP by the internal RDKit module is by far the most important feature. At least this shows, that the setup so far is correct and in fact the ML model learns basically some corrections to this internal logP model. . Lets remove unimportant features, the threshold is somewhat arbitrary, but could of course be optimized further. . feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_,X.columns),reverse=True), columns=[&#39;Value&#39;,&#39;Feature&#39;]) feature_imp = feature_imp.loc[feature_imp.Value&gt;10] feature_imp.shape . (146, 2) . Xtrain = Xtrain[feature_imp.Feature] Xval = Xval[feature_imp.Feature] . Note this kind of selection is not perfectly clean, as it would have been more correct to carry out the feature selection without peaking at the experimental training data. There are also some more elaborated (and more time-consuming) methods for feature selection, such as recursive feature elimination. . Now we do a cross-validation with the selected features. For the cross-validation the RSME (root mean squared error) should be about 0.52 with the RDKit standard descriptors. We also get the standard deviation in order to see how each fold varies from the mean. . results = cross_val_score(model, Xtrain, ytrain, cv=cv, scoring=&#39;neg_mean_squared_error&#39;, ) print(&quot; nResults: %.2f (%.2f) RMSE&quot; % ((-1 * results.mean())**0.5, (results.std())**0.5)) . Results: 0.52 (0.16) RMSE . Parameter selection . OK - now lets improve the results a bit by optimisation of the LGBM parameters. We vary the learning rate, the sub sampling, i.e. how much of the data samples is left aside for each tree (stochastic gradient boosting), and the maximal depth of the regression trees. The number of estimators we set high enough in order to give the classifier the opportunity to do early stopping by monitoring the validation set. . We use basically a gridsearch on the parameter space and here also scikit learn offers the tools for doing this, via the GridSearchCV class. Of course we do this using cross-validation in order not to overfit. . Note the refit keyword we use, it allows us to return the best estimator after the grid search. . This step may also take a while, depending on how many parameters we change. Keep in mind that each additional parameter doubles the number of runs for the grid search. Therefore, instead of a grid search sometimes more sophisticated global search algorithms are used for hyperparameter tuning. . %%time parameters = {&#39;n_estimators&#39;: [5000], &#39;learning_rate&#39;: [0.01,0.02,0.03],&#39;subsample&#39;:[0.5,0.75], &#39;max_depth&#39;: [12,15]} model = GridSearchCV(model, parameters, scoring=&#39;neg_mean_squared_error&#39;,cv=cv, n_jobs = 4,refit=True, verbose=0) model.fit(Xtrain, ytrain, early_stopping_rounds=100,eval_metric=[&#39;l1&#39;,&#39;l2&#39;], eval_set=[(Xtrain, ytrain), (Xval, yval)]) df_res = pd.DataFrame(model.cv_results_) df_res[&#39;rmse&#39;] = (-1*df_res[&#39;mean_test_score&#39;])**0.5 print(df_res[[&#39;rmse&#39;,&#39;params&#39;,&#39;rank_test_score&#39;]].sort_values(&#39;rank_test_score&#39;,ascending=True)) . The RMSE should be around 0.50 and a sensible set of parameters should be for the standard RDKit descriptors: {&#39;learning_rate&#39;: 0.02, &#39;max_depth&#39;: 12, &#39;n_estimators&#39;: 5000, &#39;subsample&#39;: 0.75} . For the fingerprints: RMSE =0.77 and some possible parameters {&#39;learning_rate&#39;: 0.1, &#39;max_depth&#39;: 15, &#39;n_estimators&#39;: 5000, &#39;subsample&#39;: 1.0} . The fingerprints based model seems to be significantly worse than the one with classical descriptors. . Note, that we deploy the model (and the selected features!), so that we can re-use it later on. We use the joblib library, which goes well with scikit-learn models, but we could also have used python pickle command here. . dump(model, &#39;lgbm_logp.joblib&#39;) dump(feature_imp.Feature, &#39;features.joblib&#39;) . [&#39;features.joblib&#39;] . Deployment &amp; Analysis of the results . Now lets check the model. We use the data from the SAMPL7 blind challenge. . df = pd.read_csv(&#39;https://raw.githubusercontent.com/samplchallenges/SAMPL7/master/physical_property/SAMPL7_molecule_ID_and_SMILES.csv&#39;) df_exp = pd.read_csv(&#39;https://raw.githubusercontent.com/samplchallenges/SAMPL7/master/physical_property/experimental_data/Experimental_Properties_of_SAMPL7_Compounds.csv&#39;) df_exp.rename({&#39;logP &#39;: &#39;logP&#39;},inplace=True,axis=1) # lets remove the ugly white space df = df.merge(df_exp[[&#39;Molecule ID&#39;,&#39;logP&#39;]],left_on=&#39;SAMPL7 Molecule ID&#39;,right_on=&#39;Molecule ID&#39;) df . SAMPL7 Molecule ID isomeric SMILES Molecule ID logP . 0 SM25 | O=C(NS(C1=CC=CC=C1)(=O)=O)CCC2=CC=CC=C2 | SM25 | 2.67 | . 1 SM26 | O=S(CCC1=CC=CC=C1)(NC(C)=O)=O | SM26 | 1.04 | . 2 SM27 | O=S(CCC1=CC=CC=C1)(NC2(C)COC2)=O | SM27 | 1.56 | . 3 SM28 | O=S(CC1(NC(C)=O)CCC2=CC=CC=C2)(C1)=O | SM28 | 1.18 | . 4 SM29 | CS(NC1(COC1)CCC2=CC=CC=C2)(=O)=O | SM29 | 1.61 | . 5 SM30 | O=S(NC1(COC1)CCC2=CC=CC=C2)(C3=CC=CC=C3)=O | SM30 | 2.76 | . 6 SM31 | O=S(NC1(COC1)CCC2=CC=CC=C2)(N(C)C)=O | SM31 | 1.96 | . 7 SM32 | CS(NC1(CSC1)CCC2=CC=CC=C2)(=O)=O | SM32 | 2.44 | . 8 SM33 | O=S(NC1(CSC1)CCC2=CC=CC=C2)(C3=CC=CC=C3)=O | SM33 | 2.96 | . 9 SM34 | O=S(NC1(CSC1)CCC2=CC=CC=C2)(N(C)C)=O | SM34 | 2.83 | . 10 SM35 | CS(N[C@@]1(C[S+]([O-])C1)CCC2=CC=CC=C2)(=O)=O | SM35 | 0.88 | . 11 SM36 | O=S(N[C@@]1(C[S+]([O-])C1)CCC2=CC=CC=C2)(C3=CC=CC=C3)=O | SM36 | 0.76 | . 12 SM37 | O=S(N[C@@]1(C[S+]([O-])C1)CCC2=CC=CC=C2)(N(C)C)=O | SM37 | 1.45 | . 13 SM38 | CS(NC1(CS(C1)(=O)=O)CCC2=CC=CC=C2)(=O)=O | SM38 | 1.03 | . 14 SM39 | O=S(NC1(CS(C1)(=O)=O)CCC2=CC=CC=C2)(C3=CC=CC=C3)=O | SM39 | 1.89 | . 15 SM40 | O=S(NC1(CS(C1)(=O)=O)CCC2=CC=CC=C2)(N(C)C)=O | SM40 | 1.83 | . 16 SM41 | O=S(NC1=NOC(C2=CC=CC=C2)=C1)(C)=O | SM41 | 0.58 | . 17 SM42 | O=S(NC1=NOC(C2=CC=CC=C2)=C1)(C3=CC=CC=C3)=O | SM42 | 1.76 | . 18 SM43 | O=S(NC1=NOC(C2=CC=CC=C2)=C1)(N(C)C)=O | SM43 | 0.85 | . 19 SM44 | O=S(NC(N=N1)=CN1C2=CC=CC=C2)(C)=O | SM44 | 1.16 | . 20 SM45 | O=S(NC(N=N1)=CN1C2=CC=CC=C2)(C3=CC=CC=C3)=O | SM45 | 2.55 | . 21 SM46 | O=S(NC(N=N1)=CN1C2=CC=CC=C2)(N(C)C)=O | SM46 | 1.72 | . Lets have a look at the molecules first. . tmp_ms = [Chem.MolFromSmiles(x) for x in df[&#39;isomeric SMILES&#39;].values] Draw.MolsToGridImage(tmp_ms,molsPerRow=4,subImgSize=(200,200)) . Now lets build a function that takes a list of SMILES and outputs the corresponding logP values using our previous build model: . def predict_logp(smiles): # generate desriptors desc_list = list(map(smiles2desc,smiles)) Xtest = pd.DataFrame(desc_list, columns = calculator.GetDescriptorNames()) # load the relevant column names columns = load(&#39;features.joblib&#39;) Xtest = Xtest[columns] # load the model model = load(&#39;lgbm_logp.joblib&#39;) ypred = model.predict(Xtest) return ypred . smiles = df[&#39;isomeric SMILES&#39;].values df[&#39;ypred&#39;] = predict_logp(smiles) mae = mean_absolute_error(df.logP, df[&#39;ypred&#39;]) mse = mean_squared_error(df.logP, df[&#39;ypred&#39;]) print(&quot;MAE: %6.2f RMSE: %6.2f&quot; % (mae,mse**0.5)) . MAE: 0.59 RMSE: 0.68 . Conclusions . Not bad - the obtained RMSE would have been around the 3rd position in the SAMPL7 logP challenge. But also note the small dataset size (n=22) and the particular domain, i.e. mostly sulfonamids for this challenge, which of course is not sufficient to get a robust statistic for general model performance. So keep in mind having always a sufficiently large and representative validation set at hand. . With a very simple setup and using a set of common python libraries we can build and deploy very accurate QSPR like machine learning models. Its very likely that this logP model could be improved with even more accurate data, machine learning models are data hungry, do not expect to get good results with a just hand ful of data points. Quite importantly, a curated dataset was used for model building, i.e. having a high noise level in the dataset usually detoriates gradient boosting regressors significantly and for such datasets more robust regressors/classifiers such as Random Forest should be used. . Below some results for different runs (the score of the internal RDKit logP model with the opera dataset is RMSE=0.87 and for the SAMPL7 dataset RMSE=0.88 by the way): . dataset RMSE,CV n dataset MAE RMSE n descriptors . OPERA | 0.52 | 10547 | SAMPL7 | 0.59 | 0.68 | 22 | RDKit MoleculeDescriptors | . OPERA | 0.50 | 13962 | SAMPL7 | 0.66 | 0.77 | 22 | RDKit MoleculeDescriptors | . OPERA | 0.87 | 10547 | SAMPL7 | 0.80 | 1.10 | 22 | RDKit Morgan Fingerprints | . OPERA | 0.78 | 13962 | SAMPL7 | 0.79 | 1.09 | 22 | RDKit Morgan Fingerprints | .",
            "url": "https://chloschen.github.io/fastpages/2020/11/22/logp-machinelearning.html",
            "relUrl": "/2020/11/22/logp-machinelearning.html",
            "date": " • Nov 22, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Python Implementation of a Lattice Gas Monte Carlo Simulation",
            "content": "This notebook contains a simple python implementation of a Monte Carlo simulation of a lattice gas (and here), which is strongly related (i.e. isomorphic) to the Ising model, a simple statistical mechanics model to describe ferromagnetism. . The lattice gas model is one of the simplest models that can describe phase transitions, such as ordered to unordered states. The volume available for a molecule is divided in cells on a regular grid. Here only the 2-dimensional case is shown with a coordination number of z=4. In three dimensions one can have a simple cubic (SC) lattice with z = 6, a body-centered cubic (BCC) lattice with z = 8, or a face- centered cubic(FCC) lattice with z = 12. . Attractive interaction only take place between nearest neighbor cells. The lattice model (Ising model) can be solved completely (i.e. no simulation or mean field approximation necessary) for the 2D dimensional case without an applied field . For all other cases only approximate solutions exist or numerical simulations have to be carried out. . This notebook is loosely based on the book &quot;Introduction to Modern Statistical Mechanics&quot; by David Chandler and on this freely available book chapter. . To speed up the computations costly operations are wrapped with a Numba decorator, which carries out a just-in-time (JIT) compilation of the underlying code. Hence, the code runs as nearly as fast as native C code! . Here we load the basic libraries. Numpy for linear algebra, matplotlib for plotting and some utilities (e.g. tqdm shows a handy progress bar in loops) . import numpy as np import matplotlib.pyplot as plt %matplotlib inline import time from tqdm.auto import tqdm, trange from numba import jit . The random seed is defined for reproducibility and some parameters are defined as the size of the (quadratic) grid, the chemical potential $ mu$ (~ magnetic moment in the Ising model) and the interaction energy $ epsilon$ and $ beta = (RT)^{-1}$. For now with some arbitrary values. . The energy of a state is computed by: . $E = mu sum_{i} sigma_{i} + sum_{i neq j} sigma_{ij} epsilon beta$ . where the indices i,j run over the lattice sites. $ sigma_{i}$ is 1 if the corresponding lattice site is occupied otherwise its zero, similarly $ sigma_{ij}$ runs only over next neighbour interactions. . np.random.seed(123) cmap = plt.cm.gray_r # reversed colour map: black 1 white 0 nsize=20 mu = 0.0 # ~ simple chemical potential - keep it zero in order to keep number of particles constant epsilon = -2.0 # interaction energy T = 500 # temperature MAX_ITER = 1000 # max ierations beta = (0.02 * T)**-1 . (0.1, -0.2) . Later on we will play with those parameters, i.e. choose a positive or negative chemical potential, increase interaction energy or temperature and see what changes and characteristics are introduced within the model. . Define some utility functions here . We are using the numba library in order to increase computation speed of python code. In order to do this one places the &#39;@jit&#39; decorator in front of a function. . @jit(nopython=True) def flip_state(a): pos = np.random.randint(nsize*nsize) tmp = a.flatten() tmp[pos] = !tmp[pos] a = tmp.reshape((nsize,nsize)) return a @jit(nopython=True) def flip_states(a,n=10): tmp = a.flatten() #poslist = np.random.randint(nsize*nsize,size=n) poslist = [np.random.randint(nsize*nsize) for x in range(n) ] for pos in poslist: tmp[pos] = not tmp[pos] a = tmp.reshape((nsize,nsize)) return a @jit(nopython=True) def move_state(a): tmp = a.copy() #select random position i = np.random.randint(nsize) j = np.random.randint(nsize) #select random move move = np.random.randint(4) # 0: top 1: left 2: down 3: right new_idx = get_neighbour_indices(i,j)[move] tmp[i,j],tmp[new_idx] = tmp[new_idx],tmp[i,j] return tmp @jit(nopython=True) def move_states(a,n=10): tmp = a.copy() #ilist = np.random.randint(nsize,size=n) # not supported by numba ilist = [np.random.randint(nsize) for x in range(n) ] jlist = [ np.random.randint(nsize) for x in range(n)] for i,j in zip(ilist,jlist): move = np.random.randint(4) # 0: top 1: left 2: down 3: right new_idx = get_neighbour_indices(i,j)[move] #print(new_idx,move) tmp[i,j],tmp[new_idx] = tmp[new_idx],tmp[i,j] #print(tmp[i,j]) return tmp . @jit(nopython=True) def pbc1(x): if x&gt;=0: return x else: return x+nsize @jit(nopython=True) def pbc2(x): if x&lt;nsize: return x else: return x-nsize @jit(nopython=True) def get_neighbour_indices(i,j): #peridoic boundary conditions top = (pbc1(i-1),j) left = (i,pbc1(j-1)) down = (pbc2(i+1),j) right = (i,pbc2(j+1)) nidxs = [top,left,down,right] return nidxs @jit(nopython=True) def compute_energy(state, verbose = False): &quot;&quot;&quot; Here we compute the energy of the full system, it would be more effcient to compute only the local energy change(s)... &quot;&quot;&quot; e = 0.0 eint = 0.0 for i in range(nsize): for j in range(nsize): e += mu * state[i,j] #print(i,j) nidxs = get_neighbour_indices(i,j) et = 0.0 for ni in nidxs: et += 0.5 *epsilon * state[i,j] * state[ni] #print(nidxs) eint += et #if verbose: # print(f&quot;mu={e:.1f} E_int={eint:.1f} beta={beta:.2f}&quot;) return beta*(e+eint) . Building the model . First we initalize a complete ordered state and plot it. . state_init = np.ones((nsize,nsize),dtype=bool) state_init[:int(nsize/2),:] = 0 # ... side by side fig=plt.figure(figsize=(8, 4)) fig.add_subplot(1, 2, 1) # subplot one plt.imshow(state_init, cmap=cmap) fig.add_subplot(1, 2, 2) # subplot two # my data is OK to use gray colormap (0:black, 1:white) s2 = move_states(state_init) plt.imshow(s2, cmap=cmap) # use appropriate colormap here . &lt;matplotlib.image.AxesImage at 0x1a92ec590c8&gt; . This gives some lowest energy boundary, similar to an ordered crystalline state. Unlike a real surface particle can just be turned off and on, i.e. basically moving without boundaries or hinderance of the other particles. . Here we compute the energy of the completely ordered low energy state and of one with some arbitrarily flipped positions for reference. . compute_energy(state_init, verbose = True) . -76.0 . compute_energy(s2,verbose = True) . -74.8 . Initialize a random state . Now lets initialize some random state and note the difference (much higher energy i.e. less interactions made between particles). . fig=plt.figure(figsize=(8, 4)) # initialize a random state state_init = np.random.rand(nsize,nsize)&gt;0.5 plt.imshow(state_init, cmap=cmap) . &lt;matplotlib.image.AxesImage at 0x1a923424508&gt; . Correspondingly the energy is now much higher than for the completely ordered state (we have no entropy term introduced, which might stabilize these messy states at higher temperatures). . print(state_init.sum()) compute_energy(state_init, True) . 199 . -38.800000000000004 . Here we just prepare some (interactive) plotting. . def pltsin(ax,ax2,at, a, e_list,e_min_list): e = e_list[-1] e_min = e_min_list[-1] ax.imshow(a, cmap=cmap) at.set_text(&quot;energy = {:6.2f} ne_min = {:6.2f}&quot;.format(e,e_min)) ax2.plot(e_list,c=&#39;black&#39;) ax2.plot(e_min_list,c=&#39;red&#39;) fig.canvas.draw() . This is the Monte-Carlo simulation loop. . @jit(nopython=True) def run_simulation(state,MAX_ITER=10000, verbose = False): e_min = compute_energy(state) state_min = state e_new,e = e_min, e_min e_list = [e_min] e_min_list = [e_min] for i in range(MAX_ITER): new_state = move_states(state,n=10) e_new = compute_energy(new_state) # accept if new energy is lower if e_new&lt;e: e = e_new state = new_state # if new energy is higher use monte-carlo criterion else: t = np.random.rand() e_delta = e_new-e_min f = -e_delta acc_str = &#39;-&#39; if np.exp(f)&gt;=t: state = new_state e = e_new acc_str = &#39;+&#39; else: pass # reject step if e&lt;e_min: e_min = e state_min = state e_list.append(e) e_min_list.append(e_min) #if verbose: pltsin(ax,ax2,at,state,e_list,e_min_list) #fig, (ax,ax2) = plt.subplots(1,2) #at = ax2.text(0,-4,&quot;&quot;,color=&#39;red&#39;) #ax.imshow(state_min, cmap=plt.cm.gray) #ax2.plot(e_min_list) #ax2.plot(e_list) return state_min,e_min_list,e_list . Run the simulation . You can iterate through these cells in order to continue the simulation with more steps. . %%time state = state_init MAX_ITER = 100000 state_min,e_min_list,e_list = run_simulation(state_init,MAX_ITER) state_init = state_min #state_min,e_min_list,e_list . Wall time: 18.2 s . fig, (ax,ax2) = plt.subplots(1,2) at = ax2.text(0,-4,&quot;&quot;,color=&#39;red&#39;) ax.imshow(state_min, cmap=cmap) ax2.plot(e_min_list) ax2.plot(e_list) . [&lt;matplotlib.lines.Line2D at 0x1a97fb47cc8&gt;] . print(state_min.sum()) compute_energy(state_min) . 199 . -55.400000000000006 . You should see some larger droples/aggregates being formed. You may play around i.e. increasing the temperature in order disturb this phase transition. At some point no droplets can be formed anymore, the corresponding temperature is called the &#39;critical&#39; temperature. .",
            "url": "https://chloschen.github.io/fastpages/2020/09/06/ising_numpy.html",
            "relUrl": "/2020/09/06/ising_numpy.html",
            "date": " • Sep 6, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Using a Recommender System for ill-defined Chemical Systems",
            "content": "Polymer systems are usually not well defined, in the sense that only the basic chemistry is known and specified, but neither the processing conditions nor the exact structure or end group chemistry is given. They are intrisically mixtures represented by a molecular weight distribution. This fact hampers any thorough description by molecular descriptors in order to develop predictive models. . The following notebook develops a predictive model for polymer solubilities in different solvents using a recommender system, without the need to use any pre-computed descriptors. . Recommender systems are well-known for describing user-item relationships such as movie recommendations. Usually a matrix of user ratings given by various users on different movies (items) is used to predict ratings for unseen movies. . Movie1 Movie2 Movie3 $ ldots$ MovieM . user1 | 5 | 3 | | | 4 | . user2 | 1 | 3 | 3 | | | . user3 | 2 | 3 | | | 4 | . $ vdots$ | | | | | | . userN | 5 | 2 | 3 | | 2 | . In this notebook we apply the same kind of model for prediction of polymer solubilities in typical solvents. In a way we treat the solvents as users and the polymers as movies, though this choice could have been interchanged. . Polymer1 Polymer2 Polymer3 $ ldots$ PolymerM . Solvent1 | 5 | 3 | | | 4 | . Solvent2 | 1 | 3 | 3 | | | . Solvent3 | 2 | 3 | | | 4 | . $ vdots$ | | | | | | . SolventN | 5 | 2 | 3 | | 2 | . The basic idea is to use so-called embeddings for both solvent and polymers that are automatically learned by predicting solubilities by gradient-descent on a suitable loss function (such as root mean squared error) and subsequent backpropagation. Those embeddings map each polymer and solvent in a characteristic position in a n-dimensional vector space, which corresponds to some kind of self-learnd feature space. . Matrix factorization . $ textbf{R} = textbf{U} times textbf{I}$ . This is basically done by learning the matrix factorisation) of the Solvent ($ textbf{U}$) and Polymer ($ textbf{I}$) embeddings from the experimental data / solubility rating ($ textbf{R}$) via the deep learning frameworks pytorch &amp; fastai. . Correlation with Chemical Descriptors . Finally we are comparing the learned embeddings / features with typical chemical descriptors computed with the RDKit library. . Loading python libraries for the notebook. We are using the fastai library and pytorch. . import os from fastai.collab import * from fastai.tabular import * from torch.nn import L1Loss,MSELoss import pandas as pd import seaborn as sns os.environ[&#39;CUDA_LAUNCH_BLOCKING&#39;] = &quot;1&quot; . Loading solubilities of 33 industrial grade polymers in 88 typical solvents extraced from the Doctoral Thesis of Charles Hansen &quot;The Three Dimensional Solubility Parameter&quot;, Danish Technical Press, 1967. The rating is from 1: fullly soluble to 6: insoluble in the respective solvent. . url = &#39;https://github.com/CHLoschen/CHLoschen.github.io/blob/master/data/Hansen_polymer_data_upload.xlsx?raw=true&#39; df = pd.read_excel(url,sheet_name=&#39;hansen_thesis_polymers_curated&#39;,index_col=0) df.head() . orig_nr Solvent A B C D E F G H ... Y Z AA AB AC AD AE AF AG AH . nr . 1 1 | Methanol | 5 | 6.0 | 4 | 5 | 4 | 5 | 6 | 1 | ... | 6 | 5 | 6 | 1 | 6 | 5 | 6 | 6 | 6 | 5.0 | . 2 2 | Ethanol 96% | 4 | 6.0 | 4 | 6 | 4 | 1 | 6 | 1 | ... | 6 | 5 | 5 | 1 | 6 | 5 | 6 | 6 | 6 | 5.0 | . 3 3 | Ethanol 99% | 5 | 6.0 | 3 | 5 | 1 | 1 | 6 | 4 | ... | 6 | 6 | 4 | 1 | 6 | 5 | 6 | 6 | 6 | 6.0 | . 4 4 | n-Propanol | 5 | 6.0 | 3 | 5 | 1 | 1 | 6 | 4 | ... | 5 | 1 | 5 | 1 | 6 | 4 | 6 | 6 | 6 | 6.0 | . 5 5 | n-Butanol | 5 | 6.0 | 3 | 5 | 1 | 1 | 6 | 5 | ... | 5 | 1 | 3 | 1 | 6 | 4 | 6 | 6 | 6 | 6.0 | . 5 rows × 35 columns . value_columns = list(df.columns) value_columns.remove(&#39;Solvent&#39;) value_columns.remove(&#39;orig_nr&#39;) df[value_columns] = df[value_columns].astype(np.float32) . Converting dataframe from a long format to a wide format, which is necessary as an input for the fastai CollabLearner Class. . # 1_soluble 6: mno visible effect df_long = pd.melt(df, id_vars=[&#39;Solvent&#39;], value_vars=value_columns, var_name=&#39;polymer&#39;,value_name=&#39;solubility&#39;) df_long.describe() df_long.hist(bins=6) . array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f89ca4284e0&gt;]], dtype=object) . df_long . Solvent polymer solubility . 0 Methanol | A | 5.0 | . 1 Ethanol 96% | A | 4.0 | . 2 Ethanol 99% | A | 5.0 | . 3 n-Propanol | A | 5.0 | . 4 n-Butanol | A | 5.0 | . ... ... | ... | ... | . 2899 Acetic acid | AH | 4.0 | . 2900 Formic acid 90% | AH | 1.0 | . 2901 Butyric acid | AH | 6.0 | . 2902 Benzaldehyde | AH | 3.0 | . 2903 Acetic anhydride | AH | 5.0 | . 2904 rows × 3 columns . df_long.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 2904 entries, 0 to 2903 Data columns (total 3 columns): # Column Non-Null Count Dtype -- -- 0 Solvent 2904 non-null object 1 polymer 2904 non-null object 2 solubility 2896 non-null float32 dtypes: float32(1), object(2) memory usage: 56.8+ KB . df_names = pd.read_excel(url,sheet_name=&#39;polymers&#39;,header=None) df_names.columns=[&#39;polymer&#39;,&#39;all&#39;,&#39;fullname&#39;] df_names.head() . polymer all fullname . 0 A | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . 1 B | Poly (methyl methacrylate), Rohm and Haas Co. | Poly (methyl methacrylate) | . 2 C | Epikote® lOOI-epoxy, Shell Chemical Co. | Epikote epoxy | . 3 D | Plexal P65-66 “4 oil length alkyd, Polyplex. | Plexal alkyd | . 4 E | Pentalyn&#39;*&#39; 830-alcohol soluble rosin resin, H... | alcohol soluble resin 830 | . df_long = df_long.merge(df_names,left_on=&#39;polymer&#39;,right_on=&#39;polymer&#39;) df_long = df_long.rename({&#39;polymer&#39;:&#39;short&#39;,&#39;fullname&#39;:&#39;polymer&#39;},axis=1) . df_long= df_long.loc[~df_long[&#39;solubility&#39;].isna()] . data = CollabDataBunch.from_df(df_long, bs=32, user_name=&#39;Solvent&#39;, item_name=&#39;polymer&#39;,rating_name=&#39;solubility&#39; ,seed=42) . top_polymers = np.asarray(list(set(df_long[&#39;polymer&#39;]))) top_solvents = df[&#39;Solvent&#39;].values # original order . Defining the loss functions (mean squared error) used to optimized the weights. . lossf = MSELossFlat() . Finally we are using 5 features for each solvent and each polymer and a sigmoidal function to squash the final values to a range between $[0.75,6.25]$. . y_range = [0.75,6.25] # best range #y_range = None #learn = collab_learner(data, n_factors=3, y_range=y_range,metrics=[rmse,mse], wd=1e-1) #learn = collab_learner(data, n_factors=4, y_range=y_range,metrics=[rmse,mse], wd=1e-1,loss_func = lossf) learn = collab_learner(data, n_factors=5, y_range=y_range,metrics=[rmse,mse], wd=1e-1) #learn = collab_learner(data, n_factors=4, y_range=y_range,use_nn=True, layers=[512],) #learn = collab_learner(data,use_nn=True, emb_szs={&#39;Solvent&#39;: 10, &#39;polymer&#39;:10}, layers=[32], y_range=y_range) #learn . learn.fit_one_cycle(5, max_lr=1.0e-1) # BEST RMSE=1.09 . epoch train_loss valid_loss root_mean_squared_error mean_squared_error time . 0 | 3.880454 | 2.393616 | 1.522278 | 2.393616 | 00:00 | . 1 | 2.349662 | 1.822205 | 1.330019 | 1.822205 | 00:00 | . 2 | 1.692601 | 1.492420 | 1.205951 | 1.492420 | 00:00 | . 3 | 1.213818 | 1.371374 | 1.153695 | 1.371374 | 00:00 | . 4 | 0.882867 | 1.348545 | 1.146253 | 1.348545 | 00:00 | . learn.fit_one_cycle(20, max_lr=1.5e-2) # BEST RMSE=1.09 . epoch train_loss valid_loss root_mean_squared_error mean_squared_error time . 0 | 0.498794 | 1.250511 | 1.099317 | 1.250511 | 00:00 | . 1 | 0.507875 | 1.251159 | 1.099401 | 1.251159 | 00:00 | . 2 | 0.544147 | 1.256568 | 1.101957 | 1.256568 | 00:00 | . 3 | 0.573578 | 1.246693 | 1.097359 | 1.246692 | 00:00 | . 4 | 0.601933 | 1.265147 | 1.105491 | 1.265147 | 00:00 | . 5 | 0.598190 | 1.250596 | 1.098781 | 1.250596 | 00:00 | . 6 | 0.607573 | 1.273278 | 1.108370 | 1.273278 | 00:00 | . 7 | 0.595005 | 1.252546 | 1.098373 | 1.252546 | 00:00 | . 8 | 0.587067 | 1.260029 | 1.101490 | 1.260029 | 00:00 | . 9 | 0.577163 | 1.248523 | 1.097305 | 1.248523 | 00:00 | . 10 | 0.567109 | 1.266701 | 1.104836 | 1.266701 | 00:00 | . 11 | 0.548015 | 1.260620 | 1.103342 | 1.260620 | 00:00 | . 12 | 0.535460 | 1.260713 | 1.101913 | 1.260713 | 00:00 | . 13 | 0.504575 | 1.255369 | 1.099162 | 1.255369 | 00:00 | . 14 | 0.504699 | 1.257184 | 1.100349 | 1.257184 | 00:00 | . 15 | 0.484491 | 1.253043 | 1.098210 | 1.253043 | 00:00 | . 16 | 0.480770 | 1.260534 | 1.101728 | 1.260534 | 00:00 | . 17 | 0.466553 | 1.258097 | 1.100510 | 1.258097 | 00:00 | . 18 | 0.456542 | 1.257746 | 1.100312 | 1.257746 | 00:00 | . 19 | 0.448606 | 1.257863 | 1.100364 | 1.257863 | 00:00 | . Some Notes . Those are just some notes from differemt optimization runs to find the best parameters. . epoch train_loss valid_loss root_mean_squared_error mean_squared_error time . 9 | 0.864711 | 1.437362 | 1.183305 | 1.437362 | 00:30 | embedding=5 no NN no range | . 9 | 0.567250 | 1.571942 | 1.240355 | 1.571942 | 00:30 | embedding=10 no NN no range | . 9 | 0.382161 | 1.630874 | 1.257383 | 1.630875 | 00:31 | embedding=20 no NN no range | . 9 | 0.600861 | 1.346427 | 1.144532 | 1.346427 | 00:31 | embedding=4 range &amp; wd | . 4 | 0.446523 | 1.271633 | 1.113335 | 1.271633 | 00:30 | embedding=4 range &amp; wd | . 4 | 0.601325 | 1.305175 | 1.128294 | 1.305175 | 00:30 | embedding=5 range &amp; wd | . 9 | 0.594458 | 1.223412 | 1.095868 | 1.223412 | 00:30 | collab_learner(data, n_factors=4, y_range=y_range, wd=1e-1) | . Best results: rmse = 1.11 . learn.save(&#39;polymer&#39;) learn.export() . learn.load(&#39;polymer&#39;); . Results . learn = load_learner(&#39;.&#39;, test=data.valid_ds.x) . preds,y = learn.get_preds(ds_type=DatasetType.Test) data.valid_ds . LabelList (579 items) x: CollabList Solvent 2-Nitropropane ; polymer Poly (methyl methacrylate); ,Solvent 2-Butoxyethanol ; polymer furfuryl alcohol resin; ,Solvent Butyric acid ; polymer styrene-butadiene (SBR); ,Solvent Mesityl oxide; polymer styrene-butadiene (SBR); ,Solvent Formic acid 90%; polymer isoprene; y: FloatList 1.0,1.0,4.0,1.0,6.0 Path: . . data.valid_ds.y[0].data y_true = np.asarray([t.data for t in data.valid_ds.y]) solvents = [t for t in data.valid_ds.x] tmp = solvents[0] tmp . CollabLine Solvent 2-Nitropropane ; polymer Poly (methyl methacrylate); . Visualization of the final predictions on the validation data set. . Bad und good solvent are identified quite well with some outliers mainly for high solubility. . sns.boxplot(y_true,preds.numpy()) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f89c2ceaf60&gt; . df_long.head() . Solvent short solubility all polymer . 0 Methanol | A | 5.0 | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . 1 Ethanol 96% | A | 4.0 | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . 2 Ethanol 99% | A | 5.0 | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . 3 n-Propanol | A | 5.0 | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . 4 n-Butanol | A | 5.0 | Lucite&#39;&quot;&#39; 2042-poly (ethyl methacrylate), E. I... | poly (ethyl methacrylate) | . datatest = CollabList.from_df(df_long,cat_names=[&#39;Solvent&#39;,&#39;polymer&#39;],cont_names=[&#39;solubility&#39;]) learn.data.add_test(datatest) preds, _ = learn.get_preds(ds_type = DatasetType.Test) . df_long[&#39;predictions&#39;] = preds.numpy() df_long[&#39;SE&#39;] = np.fabs(df_long[&#39;solubility&#39;] - df_long[&#39;predictions&#39;]) df_long[&#39;SE_mean&#39;] = df_long.groupby(&#39;polymer&#39;)[&#39;SE&#39;].transform(np.mean) . df_long.sort_values(&#39;SE&#39;,ascending=False).head(20) . Solvent short solubility all polymer predictions SE SE_mean . 679 Carbon tetrachloride | H | 1.0 | Mowilith®50-poly (vinyl acetate), Farbwerke Ho... | poly (vinyl acetate) | 5.527270 | 4.527270 | 0.648882 | . 1774 m-Cresol | U | 1.0 | Hycar®&#39; lO52-acrylonitrile-butadiene raw elast... | acrylonitrile-butadiene | 5.219611 | 4.219611 | 0.641831 | . 2297 Propylene glycol | AB | 1.0 | Cymel &quot; 300-hexamethoxy melamine, American Cya... | hexamethoxy melamine | 4.897994 | 3.897994 | 0.411346 | . 1202 Dipropyl amine | N | 1.0 | Phenodur 373U-phenol-resol resin, Chemische We... | phenol-resol resin | 4.893676 | 3.893676 | 0.765612 | . 95 2-Ethyl hexanol | B | 2.0 | Poly (methyl methacrylate), Rohm and Haas Co. | Poly (methyl methacrylate) | 5.793727 | 3.793727 | 0.753604 | . 1112 Ethanolamine | M | 1.0 | Super Beckacite&#39;® JOOI-Pure Phenolic Resin, Re... | Phenolic Resin | 4.785949 | 3.785949 | 0.443935 | . 1195 Nitromethane | N | 6.0 | Phenodur 373U-phenol-resol resin, Chemische We... | phenol-resol resin | 2.324368 | 3.675632 | 0.765612 | . 94 2-Ethyl butanol | B | 2.0 | Poly (methyl methacrylate), Rohm and Haas Co. | Poly (methyl methacrylate) | 5.592360 | 3.592360 | 0.753604 | . 1492 Formic acid 90% | Q | 2.0 | Suprasec F5100-blocked isocyanate (phenol), Im... | isocyanate (phenol) | 5.545220 | 3.545220 | 0.610754 | . 2742 m-Cresol | AG | 1.0 | Piccoumarone 450L-cumarone-indene resin, Penns... | cumarone-indene resin | 4.539486 | 3.539486 | 0.359633 | . 298 y-Butyrolactone | D | 6.0 | Plexal P65-66 “4 oil length alkyd, Polyplex. | Plexal alkyd | 2.583834 | 3.416166 | 0.526580 | . 1140 Formic acid 90% | M | 5.0 | Super Beckacite&#39;® JOOI-Pure Phenolic Resin, Re... | Phenolic Resin | 1.595325 | 3.404675 | 0.443935 | . 1952 n-Butyl lactate | X | 5.0 | Lutonal IC/123-poIy (isobutylene), Badische An... | poIy (isobutylene) | 1.686984 | 3.313016 | 0.403327 | . 996 Dioxane | L | 1.0 | Cellulose acetate, Cellidora A-Bayer AG. | Cellulose acetate | 4.274647 | 3.274647 | 0.695053 | . 1441 Propylene carbonate | Q | 1.0 | Suprasec F5100-blocked isocyanate (phenol), Im... | isocyanate (phenol) | 4.267636 | 3.267636 | 0.610754 | . 2826 Ethylene glycol | AH | 1.0 | Milled wood lignin—Special sample from prof. A... | lignin | 4.257072 | 3.257072 | 0.824119 | . 732 Dioxane | I | 6.0 | Plastopal H-urea formaldehyde resin, Badische ... | urea formaldehyde resin | 2.810896 | 3.189104 | 0.639131 | . 436 Formic acid 90% | E | 6.0 | Pentalyn&#39;*&#39; 830-alcohol soluble rosin resin, H... | alcohol soluble resin 830 | 2.854373 | 3.145627 | 0.636493 | . 1921 a-bromonaphthaline | V | 5.0 | Cariflex IR 305-isoprene raw elastomer, Shell ... | isoprene | 1.868847 | 3.131153 | 0.450882 | . 2837 Butyl dioxitol | AH | 1.0 | Milled wood lignin—Special sample from prof. A... | lignin | 4.109126 | 3.109126 | 0.824119 | . df_long.loc[df_long[&#39;polymer&#39;] == &#39;Nitrocellulose&#39;].sort_values(&#39;SE&#39;,ascending=False).head(20) . Solvent short solubility all polymer predictions SE SE_mean . 820 Dioxane | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.914037 | 3.085963 | 0.612327 | . 803 1,3 Butanediol | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 3.071082 | 2.928918 | 0.612327 | . 862 2,2-Dichlorodiethylether | J | 5.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.354406 | 2.645594 | 0.612327 | . 839 Isoamyl acetate | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 3.595124 | 2.595124 | 0.612327 | . 846 Aniline | J | 3.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 1.085439 | 1.914561 | 0.612327 | . 840 Isobutyl isobutyrate | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.814014 | 1.814014 | 0.612327 | . 831 Diisobutyl ketone | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.727038 | 1.727038 | 0.612327 | . 847 Nitrobenzene | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.381097 | 1.381097 | 0.612327 | . 793 Ethanol 96% | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 4.674847 | 1.325153 | 0.612327 | . 878 Benzaldehyde | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.310237 | 1.310237 | 0.612327 | . 808 n-Butyl lactate | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 2.249110 | 1.249110 | 0.612327 | . 871 Styrene | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 4.909613 | 1.090387 | 0.612327 | . 802 Ethylene glycol | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 4.988702 | 1.011298 | 0.612327 | . 811 2-Butoxyethanol | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 1.999578 | 0.999578 | 0.612327 | . 857 Ethylene chloride | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 5.137198 | 0.862802 | 0.612327 | . 819 Furan | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 5.153099 | 0.846901 | 0.612327 | . 841 Acetonitrile | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 1.840003 | 0.840003 | 0.612327 | . 795 n-Propanol | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 5.170982 | 0.829018 | 0.612327 | . 792 Methanol | J | 1.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 1.807023 | 0.807023 | 0.612327 | . 867 Benzene | J | 6.0 | % Sec. Nitrocellulose-!! 23, A. Hagedorn and C... | Nitrocellulose | 5.209587 | 0.790413 | 0.612327 | . sbn.boxplot(df_long[&#39;solubility&#39;],df_long[&#39;predictions&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f89c2c3ba90&gt; . from sklearn.metrics import mean_absolute_error, mean_squared_error mae = mean_absolute_error(df_long[&#39;solubility&#39;],df_long[&#39;predictions&#39;]) rmse = mean_squared_error(df_long[&#39;solubility&#39;],df_long[&#39;predictions&#39;])**0.5 print(&quot;MAE: {:6.4f} RMSE: {:6.3f}&quot;.format(mae,rmse)) . MAE: 0.5297 RMSE: 0.781 . Interpretation . Here we try to interpret the learned embeddings, in particular if they correspond to some physicochemical properties and/or descriptors. . learn.load(&#39;polymer&#39;); . polymer_bias = learn.bias(top_polymers, is_item=True) polymer_bias.shape . torch.Size([33]) . mean_ratings = df_long.groupby(&#39;polymer&#39;)[&#39;solubility&#39;].mean() polymer_ratings = [(b.item(), i, mean_ratings.loc[i]) for i,b in zip(top_polymers,polymer_bias)] . item0 = lambda o:o[0] . sorted(polymer_ratings, key=item0)[:15] . [(-1.511541724205017, &#39;Polyester&#39;, 1.6896552), (-1.458953857421875, &#39;Phenolic Resin&#39;, 1.3295455), (-1.4562469720840454, &#39;hexamethoxy melamine&#39;, 1.2613636), (-1.1389750242233276, &#39;Plexal alkyd&#39;, 1.9090909), (-0.8391879200935364, &#39;coconut oil-phthalic anhydride alkyd&#39;, 1.8863636), (-0.7986485362052917, &#39;pentaerythritol ester of rosin&#39;, 2.034091), (-0.6752591729164124, &#39;alcohol soluble resin 830&#39;, 2.0), (-0.6638078689575195, &#39;Epikote epoxy&#39;, 2.1363637), (-0.6293772459030151, &#39;Ester gum&#39;, 2.1704545), (-0.5470041632652283, &#39;phenol-resol resin&#39;, 3.2045455), (-0.5220370888710022, &#39;poly (ethyl methacrylate)&#39;, 2.0113637), (-0.44126516580581665, &#39;poly (vinyl acetate)&#39;, 2.1363637), (-0.3716408312320709, &#39;akohol soluble resin 255&#39;, 2.8181818), (-0.36254385113716125, &#39;furfuryl alcohol resin&#39;, 2.7954545), (-0.29995399713516235, &#39;poly (vinyl butyral)&#39;, 2.3181818)] . movie_w = learn.weight(top_polymers, is_item=True) movie_w.shape . torch.Size([33, 5]) . movie_pca = movie_w.pca(3) movie_pca.shape . torch.Size([33, 3]) . fac0,fac1,fac2 = movie_pca.t() polymer_comp = [(f, i) for f,i in zip(fac0, top_polymers)] . sorted(polymer_comp, key=itemgetter(0), reverse=True)[:10] . [(tensor(2.4272), &#39;terpene resin&#39;), (tensor(2.3092), &#39;petroleum hydrocarbon resin&#39;), (tensor(2.0871), &#39;poIy (isobutylene)&#39;), (tensor(1.9997), &#39;isoprene&#39;), (tensor(1.9296), &#39;cis poly butadiene &#39;), (tensor(1.8371), &#39;styrene-butadiene (SBR)&#39;), (tensor(1.4173), &#39;Polystyrene&#39;), (tensor(1.2220), &#39;cumarone-indene resin&#39;), (tensor(1.1789), &#39;Ester gum&#39;), (tensor(0.7506), &#39;pentaerythritol ester of rosin&#39;)] . sorted(polymer_comp, key=itemgetter(0))[:10] . [(tensor(-2.0999), &#39;phenol-resol resin&#39;), (tensor(-1.9046), &#39;akohol soluble resin 255&#39;), (tensor(-1.8175), &#39; isocyanate (phenol)&#39;), (tensor(-1.6700), &#39;lignin&#39;), (tensor(-1.6170), &#39;Nitrocellulose&#39;), (tensor(-1.5084), &#39;urea formaldehyde resin&#39;), (tensor(-1.2535), &#39;furfuryl alcohol resin&#39;), (tensor(-1.2297), &#39;Polyester&#39;), (tensor(-1.1110), &#39;Cellulose acetate&#39;), (tensor(-1.0091), &#39;poly (vinyl acetate)&#39;)] . polymer_comp = [(f, i) for f,i in zip(fac1, top_polymers)] . sorted(polymer_comp, key=itemgetter(0), reverse=False)[:10] . [(tensor(-2.0351), &#39;polyamide&#39;), (tensor(-1.8825), &#39;poIy (isobutylene)&#39;), (tensor(-1.8567), &#39;poly (vinyl butyral)&#39;), (tensor(-1.7696), &#39;akohol soluble resin 255&#39;), (tensor(-1.4629), &#39;alcohol soluble resin 830&#39;), (tensor(-1.4358), &#39;urea formaldehyde resin&#39;), (tensor(-1.0520), &#39;pentaerythritol ester of rosin&#39;), (tensor(-0.7186), &#39;hexamethoxy melamine&#39;), (tensor(-0.7005), &#39;Ester gum&#39;), (tensor(-0.6341), &#39;Phenolic Resin&#39;)] . sorted(polymer_comp, key=itemgetter(0), reverse=True)[:10] . [(tensor(1.4824), &#39;Nitrocellulose&#39;), (tensor(1.3826), &#39;acrylonitrile-butadiene&#39;), (tensor(1.3192), &#39;Polystyrene&#39;), (tensor(1.2893), &#39;Poly (methyl methacrylate)&#39;), (tensor(1.2830), &#39;poly (vinyl chloride)&#39;), (tensor(1.1330), &#39;chlorinated poly (propylene)&#39;), (tensor(0.8796), &#39;Cellulose acetate&#39;), (tensor(0.7444), &#39;cumarone-indene resin&#39;), (tensor(0.6660), &#39;Polyester&#39;), (tensor(0.6078), &#39;styrene-butadiene (SBR)&#39;)] . top_polymers . array([&#39;poly (ethyl methacrylate)&#39;, &#39;poly (vinyl chloride)&#39;, &#39;styrene-butadiene (SBR)&#39;, &#39;urea formaldehyde resin&#39;, &#39;Nitrocellulose&#39;, &#39;Polystyrene&#39;, &#39;Epikote epoxy&#39;, &#39;poIy (isobutylene)&#39;, &#39;Phenolic Resin&#39;, &#39;terpene resin&#39;, &#39;petroleum hydrocarbon resin&#39;, &#39;cumarone-indene resin&#39;, &#39;acrylonitrile-butadiene&#39;, &#39;phenol-resol resin&#39;, &#39;Plexal alkyd&#39;, &#39;pentaerythritol ester of rosin&#39;, &#39;alcohol soluble resin 830&#39;, &#39;cis poly butadiene &#39;, &#39;hexamethoxy melamine&#39;, &#39;polyamide&#39;, &#39;isoprene&#39;, &#39;Polyester&#39;, &#39;Cellulose acetate&#39;, &#39;furfuryl alcohol resin&#39;, &#39;poly (vinyl acetate)&#39;, &#39;lignin&#39;, &#39;coconut oil-phthalic anhydride alkyd&#39;, &#39;chlorinated poly (propylene)&#39;, &#39;Poly (methyl methacrylate)&#39;, &#39; isocyanate (phenol)&#39;, &#39;poly (vinyl butyral)&#39;, &#39;akohol soluble resin 255&#39;, &#39;Ester gum&#39;], dtype=&#39;&lt;U36&#39;) . print(len(top_polymers)) idxs = np.random.choice(len(top_polymers), 33, replace=False) X = fac0[idxs] Y = fac1[idxs] plt.figure(figsize=(15,15)) plt.scatter(X, Y) for i, x, y in zip(top_polymers[idxs], X, Y): plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11) plt.show() . 33 . The figure above shows the polymer features space projected onto the 2 main principle components. . Solvents . print(top_solvents) solvent_w = learn.weight(top_solvents, is_item=False) solvent_w.shape . [&#39;Methanol &#39; &#39;Ethanol 96%&#39; &#39;Ethanol 99%&#39; &#39;n-Propanol &#39; ... &#39;Formic acid 90%&#39; &#39; Butyric acid &#39; &#39;Benzaldehyde &#39; &#39;Acetic anhydride &#39;] . torch.Size([88, 5]) . solvent_pca = solvent_w.pca(3) solvent_pca.shape . torch.Size([88, 3]) . fac0,fac1,fac2 = solvent_pca.t() solvent_comp = [(f, i) for f,i in zip(fac0, top_solvents)] sorted(solvent_comp, key=itemgetter(0), reverse=True)[:10] . [(tensor(1.9440), &#39;Dipropylene glycol&#39;), (tensor(1.7700), &#39;Diethylene glycol&#39;), (tensor(1.6478), &#39;Dimethyl sulphoxide&#39;), (tensor(1.3284), &#39;Acetic acid &#39;), (tensor(1.3157), &#39;Ethyl lactate &#39;), (tensor(1.3095), &#39;Methyl Cellosolve &#39;), (tensor(1.2806), &#39;Ethanolamine &#39;), (tensor(1.2013), &#39;Methanol &#39;), (tensor(1.1993), &#39;Methyl dioxitol &#39;), (tensor(1.1856), &#39;y-Butyrolactone &#39;)] . sorted(solvent_comp, key=itemgetter(0), reverse=False)[:10] . [(tensor(-1.6316), &#39;Ethyl benzene &#39;), (tensor(-1.5449), &#39;Benzene &#39;), (tensor(-1.4641), &#39;1,1,1 Trichloroethane&#39;), (tensor(-1.3850), &#39;Isoamyl acetate &#39;), (tensor(-1.3618), &#39;Cyclohexylchloride &#39;), (tensor(-1.3517), &#39;n-Butyl acetate &#39;), (tensor(-1.3500), &#39;Xylene &#39;), (tensor(-1.3242), &#39;Isobutyl isobutyrate&#39;), (tensor(-1.2733), &#39;Toluene &#39;), (tensor(-1.2611), &#39;Methylene chloride &#39;)] . print(len(top_solvents)) idxs = np.random.choice(len(top_solvents), 50, replace=False) X = fac0[idxs] Y = fac1[idxs] plt.figure(figsize=(15,15)) plt.scatter(X, Y) for i, x, y in zip(top_solvents[idxs], X, Y): plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11) plt.show() . 88 . The figure above shows the solvent features space projected onto the 2 main principle components. . Correlation of Learned Embeddings with RDKit descriptors . First we have to install the cheminformatic package RDKit via conda, which may take some time. . # uncomment those lines below #!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh #!chmod +x Miniconda3-latest-Linux-x86_64.sh #!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local #!time conda install -q -y -c conda-forge rdkit . import sys sys.path.append(&#39;/usr/local/lib/python3.7/site-packages/&#39;) from rdkit import Chem from rdkit.ML.Descriptors import MoleculeDescriptors from rdkit.Chem import Descriptors . len(Descriptors._descList) . 200 . df_desc = pd.read_excel(url,sheet_name=&#39;solvent_descriptors&#39;) df_desc . orig_nr SMILES curated_name original name . 0 1 | CO | Methanol | Methanol | . 1 2 | CCO | Ethanol | Ethanol 96% | . 2 3 | CCO | Ethanol | Ethanol 99% | . 3 4 | CCCO | n-Propanol | n-Propanol | . 4 5 | CCCCO | n-Butanol | n-Butanol | . ... ... | ... | ... | ... | . 83 66 | OC(C)=O | Acetic acid | Acetic acid | . 84 67 | OC=O | Formic acid | Formic acid 90% | . 85 67A | CCCC(=O)O | Butyric acid | Butyric acid | . 86 68 | O=Cc1ccccc1 | Benzaldehyde | Benzaldehyde | . 87 69 | CC(OC(C)=O)=O | Acetic anhydride | Acetic anhydride | . 88 rows × 4 columns . df_rdkit = df_desc[[&#39;SMILES&#39;,&#39;original name&#39;]] #df_rdkit[&#39;MOL&#39;] = df_rdkit[&#39;SMILES&#39;].apply(lambda x: Chem.MolFromSmiles(x)) df_rdkit . SMILES original name . 0 CO | Methanol | . 1 CCO | Ethanol 96% | . 2 CCO | Ethanol 99% | . 3 CCCO | n-Propanol | . 4 CCCCO | n-Butanol | . ... ... | ... | . 83 OC(C)=O | Acetic acid | . 84 OC=O | Formic acid 90% | . 85 CCCC(=O)O | Butyric acid | . 86 O=Cc1ccccc1 | Benzaldehyde | . 87 CC(OC(C)=O)=O | Acetic anhydride | . 88 rows × 2 columns . #compute all descriptors for smiles and return dictionary with key: desc_name and value: desc. value def calc_descrs_for_smiles(smi,descList): m = Chem.MolFromSmiles(smi) if m is None: return dict(zip(descList,[None]*(len(descList)))) fns = [(x,y) for x,y in Descriptors.descList if x in descList] res = {} for x,y in fns: res[x] = y(m) res[&#39;SMILES&#39;] = smi return res . def compute_corr(df_tmp,threshold=0.4): # Compute the correlation matrix corr = df_tmp._get_numeric_data().corr()**2 # Generate a mask for the upper triangle mask = np.triu(np.ones_like(corr, dtype=np.bool)) # Set up the matplotlib figure f, ax = plt.subplots(figsize=(11, 9)) # Generate a custom diverging colormap cmap = sbn.diverging_palette(220, 10, as_cmap=True) # Draw the heatmap with the mask and correct aspect ratio ax = sbn.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, center=0, square=True, linewidths=.5, cbar_kws={&quot;shrink&quot;: .5}) return ax,corr . descList = [desc[0] for desc in Descriptors.descList] desc_corr = [&#39;MinPartialCharge&#39;, &#39;MaxAbsPartialCharge&#39;, &#39;PEOE_VSA6&#39;, &#39;SMR_VSA1&#39;,&#39;TPSA&#39;, &#39;NOCount&#39;, &#39;NumHAcceptors&#39;, &#39;MolLogP&#39;,&#39;EState_VSA10&#39;, &#39;NHOHCount&#39;, &#39;NumHDonors&#39;, &#39;fr_Al_OH&#39;,&#39;fr_Al_OH_noTert&#39;,&#39;qed&#39;] descList = desc_corr descList . [&#39;MinPartialCharge&#39;, &#39;MaxAbsPartialCharge&#39;, &#39;PEOE_VSA6&#39;, &#39;SMR_VSA1&#39;, &#39;TPSA&#39;, &#39;NOCount&#39;, &#39;NumHAcceptors&#39;, &#39;MolLogP&#39;, &#39;EState_VSA10&#39;, &#39;NHOHCount&#39;, &#39;NumHDonors&#39;, &#39;fr_Al_OH&#39;, &#39;fr_Al_OH_noTert&#39;, &#39;qed&#39;] . descs=[] for smi in set(df_rdkit[&#39;SMILES&#39;].values): res = calc_descrs_for_smiles(smi,descList) descs.append(res) . df_rdkit = df_rdkit.merge(pd.DataFrame(descs),left_on=&#39;SMILES&#39;,right_on=&#39;SMILES&#39;,how=&#39;left&#39;) . df_rdkit . SMILES original name qed MinPartialCharge MaxAbsPartialCharge PEOE_VSA6 SMR_VSA1 TPSA EState_VSA10 NHOHCount NOCount NumHAcceptors NumHDonors MolLogP fr_Al_OH fr_Al_OH_noTert . 0 CO | Methanol | 0.385284 | -0.399630 | 0.399630 | 0.000000 | 5.106527 | 20.23 | 0.000000 | 1 | 1 | 1 | 1 | -0.3915 | 1 | 1 | . 1 CCO | Ethanol 96% | 0.406808 | -0.396664 | 0.396664 | 0.000000 | 5.106527 | 20.23 | 0.000000 | 1 | 1 | 1 | 1 | -0.0014 | 1 | 1 | . 2 CCO | Ethanol 99% | 0.406808 | -0.396664 | 0.396664 | 0.000000 | 5.106527 | 20.23 | 0.000000 | 1 | 1 | 1 | 1 | -0.0014 | 1 | 1 | . 3 CCCO | n-Propanol | 0.463784 | -0.396387 | 0.396387 | 6.923737 | 5.106527 | 20.23 | 0.000000 | 1 | 1 | 1 | 1 | 0.3887 | 1 | 1 | . 4 CCCCO | n-Butanol | 0.512822 | -0.396377 | 0.396377 | 13.344559 | 5.106527 | 20.23 | 0.000000 | 1 | 1 | 1 | 1 | 0.7788 | 1 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 83 OC(C)=O | Acetic acid | 0.429883 | -0.481433 | 0.481433 | 0.000000 | 9.901065 | 37.30 | 0.000000 | 1 | 2 | 1 | 1 | 0.0909 | 0 | 0 | . 84 OC=O | Formic acid 90% | 0.380161 | -0.483467 | 0.483467 | 0.000000 | 9.901065 | 37.30 | 0.000000 | 1 | 2 | 1 | 1 | -0.2992 | 0 | 0 | . 85 CCCC(=O)O | Butyric acid | 0.543441 | -0.481231 | 0.481231 | 6.923737 | 9.901065 | 37.30 | 4.794537 | 1 | 2 | 1 | 1 | 0.8711 | 0 | 0 | . 86 O=Cc1ccccc1 | Benzaldehyde | 0.495636 | -0.297896 | 0.297896 | 30.331835 | 4.794537 | 17.07 | 4.794537 | 0 | 1 | 1 | 0 | 1.4991 | 0 | 0 | . 87 CC(OC(C)=O)=O | Acetic anhydride | 0.321470 | -0.393562 | 0.393562 | 0.000000 | 14.325937 | 43.37 | 9.589074 | 0 | 3 | 3 | 0 | 0.0960 | 0 | 0 | . 88 rows × 16 columns . df_rdkit[&#39;FAC0&#39;] = fac0 df_rdkit[&#39;FAC1&#39;] = fac1 df_rdkit[&#39;FAC2&#39;] = fac2 . ax, corr = compute_corr(df_rdkit) . Variables space projected on the first principle component (FAC0) shows strong correlation with logP and TPSA (Topological polar surface area). . The second principle component (FAC1) shows some correlation with the EState_VSA10 and the number of H-bond acceptors and Donors. . It seems that the colloborative filtering model learned something about molecular polarity and basic chemical concepts! . corr[&#39;FAC0&#39;].sort_values(ascending=False) . FAC0 1.000000e+00 MolLogP 6.002239e-01 TPSA 5.035388e-01 MinPartialCharge 4.231362e-01 MaxAbsPartialCharge 4.074169e-01 NOCount 4.009380e-01 SMR_VSA1 3.881399e-01 NumHAcceptors 3.751594e-01 NumHDonors 3.648076e-01 PEOE_VSA6 3.623790e-01 NHOHCount 3.359465e-01 fr_Al_OH 3.092490e-01 fr_Al_OH_noTert 2.892210e-01 qed 2.696957e-02 EState_VSA10 1.967952e-03 FAC2 7.288461e-15 FAC1 5.085565e-16 Name: FAC0, dtype: float64 . corr[&#39;FAC1&#39;].sort_values(ascending=False) . FAC1 1.000000e+00 EState_VSA10 3.010945e-01 NumHDonors 1.808664e-01 NHOHCount 1.489846e-01 fr_Al_OH_noTert 1.384980e-01 fr_Al_OH 1.297483e-01 NOCount 9.068335e-02 qed 8.447308e-02 NumHAcceptors 7.801174e-02 PEOE_VSA6 6.740623e-02 TPSA 2.230087e-02 SMR_VSA1 1.719035e-02 MolLogP 2.867912e-03 MinPartialCharge 1.778389e-04 MaxAbsPartialCharge 4.117874e-06 FAC2 5.845118e-15 FAC0 5.085565e-16 Name: FAC1, dtype: float64 .",
            "url": "https://chloschen.github.io/fastpages/2020/03/01/collabfilter.html",
            "relUrl": "/2020/03/01/collabfilter.html",
            "date": " • Mar 1, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "A Short Interactive Introduction to Python",
            "content": "This Python introductions aims at readers such as chemists and engineers with some programming background. Its intention is to give you a rough overview on the key features of the Python programming language. If you are completely new to programming, you may want to check this nice introduction first https://wiki.python.org/moin/BeginnersGuide/NonProgrammers. . It is also hosted on the google colab platform and only a web browser is needed to start it. . We will discuss a bit the differences to other languages, but we will also explain or provide links for most of the concepts mentioned here, so do not worry if some of those are not yet familiar to you. . Some key features of Python . Python is a scripting language. (There is no compiled binary code per default) | It is procedural (i.e. you can program with classic functions, that take parameters) | it is object-oriented (you can use more complex structures, that can hold several variables) | it has some functional programming features as well (e.g. lambda functions, map, reduce &amp; filter, for more information see https://en.wikipedia.org/wiki/Functional_programming) | . What makes Python special... . Indendation is used to organize code, i.e. to define blocks of code space or tabs are used (no curly brackets, semi-colons etc, no &quot;;&quot; or &quot;{}&quot;) | variables can hold any type | all variables are objects | great support for interactive use (like in this jupyter notebook here!) | Many specialized libraries, in particular scientific libraries are available, where the performance intensive part is done by C/C++/Fortran and the control/IO is done via Python | . Assignment of a variable . a = 1.5 # click the cell and press SHIFT+RETURN to run the code. This line is a comment a . 1.5 . All variables are objects, use type() function to get the type. In this case: a is of the type &quot;float&quot; (short for floating point number). Comments are declared with the hashtag # in Python. . type(a) . float . Variables can be easily re-defined, here variable a becomes an integer: . a = 1 . type(a) . int . The type of a variable is determined by assignment! There are no context prefixes like @, %, $ like in e.g. Perl . . A simple Python program . Below is a very simple Python program printing something, and demonstrating some basic features. A lot of useful functionality in Python is kept in external libraries that has to be imported before use with the import statement. Also, functions have of course to be defined prior to use. . By the way, note how identation is used to define code blocks. In Python you can use either spaces or tabs to indent your code. In Python3 mixing of tabs and spaces is not allowed, and the use of 4 consecutive spaces is recommended. . import os # definition of a python function def hello(): # get current path as a string and assign it to variable current_dir = os.getcwd() # concatentate strings and print them print(&#39;Hello world from &#39;+current_dir+&#39; !&#39;) # do not forget to call the function hello() . Hello world from /content ! . If we were not in an interactive session, we would save this chunk of code to a file, e.g. hello_word.py and run that by invoking: python hello_word.py on the command line. . . IF statement . if statements are pretty straightforward, there is no &quot;THEN&quot; and indentation helps to group the if and the else (or elif means else if) block. . a = 3.0 if a &gt; 2: print(a) if not (isinstance(a,int)): print(&quot;a is not an integer&quot;) else: print(&quot;Hmm, we should never be here...&quot;) . Since Python 3, the print statement is a proper function, in Python 2 one could do something like (i.e. without parentheses): . print &quot;a is not an integer&quot; . which is no longer possible. It is strongly recommended to use Python 3 as Python 2 is no longer maintained and many external libraries have switched meanwhile competely to Python 3. . Logical negation: if not . Checking of variable type: isinstance(variable,type) . isinstance(a,float) . True . . FOR LOOPS . for i in range(10): print(i) . 0 1 2 3 4 5 6 7 8 9 . The Python range function is somewhat special and for loops look somewhat different, than in other languages: . Python: for i in range(start=0, stop=10, step=1): | JAVA/C: for (int i=0; i&lt;10; i++) {} | Fortran: do i=0,9, end do | . Go on and manipulate the code above to check the effects. . Looping over lists (which will be explained below) is quite simple as well: . drugs = [&#39;ibuprofen&#39;,&#39;paracetamol&#39;,&#39;aspirin&#39;] for d in drugs: print(d) . ibuprofen paracetamol aspirin . Some standard keywords are used to control behaviour inside the loop: . continue: continue to next iteration of the loop | break: leave/exit the loop | . for d in drugs: if d==&#39;paracetamol&#39;: continue print(d) . ibuprofen aspirin . . Python Data Types . type example comment . int | i=1 | Integer: 0,1,2,3 | . boolean | b=False | bolean value (True/False) | . float | x=0.1 | floating point number | . str | s = &quot;how are you?&quot; | String | . list | l = [1,2,2,50,7] | Changeable list with order | . set | set([1,2,2,50,7])==set([1,2,50,7]) | Changeable set (list of unique elements) without order | . tuple | t = (99.9,2,3,&quot;aspirin&quot;) | &quot;Tuple&quot;: Unchangeable ordered list, used e.g. for returning function values | . dict | d = {“hans“: 123, “peter“:344, “dirk“: 623} | Dictionary to save key/value pairs | . The table shows the most important data types in Python. There are more specialized types e.g. https://docs.python.org/3/library/collections.html. Some useful data types are provided by external libraries, such as pandas (Python for data analysis: https://pandas.pydata.org/) . In general, the object oriented features in Python can be used to declare your own and special types/classes. . . Lists . In Python a list is a collection of elements that are ordered and changeable. . integer_list = [10,20,0,5] mixed_list = [&quot;hello&quot;,1,5.0,[2,3]] . List elements can themselves be a list and can contain different types. Accessing elements in the list is done via their indices (position in the list): . print(integer_list[2]) print(integer_list[1:3]) mixed_list[-1] . 0 [20, 0] . [2, 3] . Note, how indexing starts at index 0, which is the first element in the list. The [1:3] operation in the example is called slicing and is useful to get subsets of lists or arrays. The last element of an array can be accessed with the index -1. Manipulating and working with lists: . integer_list = [5,10,20,0,5] integer_list.append(42) print(len(integer_list)) integer_list . 6 . [5, 10, 20, 0, 5, 42] . Lists can be sorted: . integer_list.sort(reverse=True) integer_list . [42, 20, 10, 5, 5, 0] . Check if some element is contained within the list or find its index: . print(10 in integer_list) print(integer_list.index(10)) . True 2 . List can be turned into sets (only unique elements): . Indented block . set(integer_list) . {0, 5, 10, 20, 42} . Dictionaries . Dictionaries are very handy data types and consists of key-value pairs. They may also be called maps or associatve arrays. . en_de = {&#39;red&#39;:&#39;rot&#39;, &#39;blue&#39;:&#39;blau&#39;} en_de[&#39;black&#39;] = &#39;schwarz&#39; en_de[&#39;cyan&#39;] = None en_de . {&#39;black&#39;: &#39;schwarz&#39;, &#39;blue&#39;: &#39;blau&#39;, &#39;cyan&#39;: None, &#39;red&#39;: &#39;rot&#39;} . Dictionaries are a collection of key, e.g. &#39;red&#39; and value, e.g. &#39;rot&#39; pairs, where both can of course be of different types. It is important to note that they maintain no specific order. For an ordered dictionary use a special type OrderedDict (https://docs.python.org/3/library/collections.html#collections.OrderedDict). There are several ways of accessing dictionaries: . en_de[&#39;red&#39;] . &#39;rot&#39; . One can easily iterated over an dictionary: . for key in en_de: print(key, en_de[key]) . red rot blue blau black schwarz cyan None . And they are used a lot in Python, e.g. the current environmental variables are saved in dictionary (os.environ): . import os os.environ[&#39;PATH&#39;] . &#39;/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/opt/bin&#39; . Python functions . Python functions are declared with the def keyword followed by a function name and a parameter list. Within the parameter list default parameters can be specified: . def test_function(name=&#39;paracetamol&#39;): print(&#39;There is no &#39;+name+&#39; left.&#39;) test_function() test_function(&#39;aspirin&#39;) . There is no paracetamol left. There is no aspirin left. . Return results of function with the return statement, in this case we generate a string with the function and print it later, i.e. outside the function: . def test_function(name=&#39;paracetamol&#39;): answer = &#39;There is no &#39;+name+&#39; left.&#39; return answer print(test_function()) print(test_function(&#39;aspirin&#39;)) . There is no paracetamol left. There is no aspirin left. . Its also possible to return several return values as a tuple, e.g. return answer,status . . Type conversion &amp; casting . Sometimes it is necessary to convert variables from one type to another, e.g. convert a float to an int, or a an int to an str. That is where conversion functions come into play. Unlike in other languages types are converted via functions, where the return value is the converted type. . function converting from converting to . int() | string, floating point | integer | . float() | string, integer | floating point | . str() | integer, float, list, tuple, dictionary | string | . list() | string, tuple, dictionary | list | . tuple() | string, list | tuple | . import math # not sure why one wants to do this :-) int(math.pi) . 3 . float(&#39;1.999&#39;) . 1.999 . list(&#39;paracetamol&#39;) # create a list of characters! . [&#39;p&#39;, &#39;a&#39;, &#39;r&#39;, &#39;a&#39;, &#39;c&#39;, &#39;e&#39;, &#39;t&#39;, &#39;a&#39;, &#39;m&#39;, &#39;o&#39;, &#39;l&#39;] . list((1,2,3,6,8)) # creates a list from a tuple . [1, 2, 3, 6, 8] . &#39;the answer is &#39;+str(42) # before concatentation integer or float should be converted to string . &#39;the answer is 42&#39; . Implicit (automatic) conversion takes place in Python to avoid data loss or loss in accuracy: . a = 2 print(type(a)) b = 4.5 print(type(b)) c = b / a print(type(c)) c . &lt;class &#39;int&#39;&gt; &lt;class &#39;float&#39;&gt; &lt;class &#39;float&#39;&gt; . 2.25 . Note, that in this example the implicit conversion avoid data loss by conversion of integer a to a floating point number. . . Object oriented progamming . Object oriented programming is a huge field of its own, and we will not go into details here. Objects are kind of complex variables that themselves can contain different variables and functions. There a implemented in the code via so-called classes. In a way a class defines the behaviour of objects and specific objects are created during runtime. Classes relate to objects as types (e.g. int) to a specific variable (e.g. a). As such, in Python there is no real difference between a class and a type: Each variable is an object of a certain type/class. New classes in Python are defined the following way: . class Greeting: def __init__(self, name): self.name = name def say_hello(self): print(&#39;Hi &#39;+self.name) . This code has created the class Greeting with its function say_hello. __init__ defines the so called constructor, which is called when the object is created. Object variable are saved using self keyword. Objects can be created and its function be called: . x1 = Greeting(&#39;Greta&#39;) x1.say_hello() . Hi Greta . Object variables can be accessed directly: . x1.name . &#39;Greta&#39; . Import statements in Python . Python comes with a lot of useful libraries. Some are contained in a default installation, some have to be installed with tools like pip or conda. The most conveniant way to install new packages/libraries in particular for scientific purposes is to use an installation like Anaconda (https://www.anaconda.com/). . Once a library is available it can be imported with an import statement. Import the whole library: . import math print(math.cos(math.pi)) . -1.0 . Import a module or function from a library: . from math import cos, pi print(cos(pi)) . -1.0 . Import and use an acronym for use: . import numpy as np array = np.asarray([1.0,2.0,1.0]) . . . Python Libraries . There a lot of useful Python libraries available. Some of those have been established a kind of standard for scientific applications: . NumPy: Array &amp; matrices &amp; linear algebra (https://numpy.org/) | SciPy: Numerical routines for integration, optimization, statistics etc. (https://www.scipy.org/scipylib/index.html) | matplotlib: a Python 2D plotting library which produces publication quality figures( https://matplotlib.org/) | scitkit-learn: machine learning in Python (https://scikit-learn.org/stable/) | Pandas: data structures (&quot;dataframes&quot;) and data analysis tool (https://pandas.pydata.org/) | . For chemistry related applications: . RDKit: open-source cheminformatics (https://www.rdkit.org/) | ASE: setting up, manipulating, running, visualizing and analyzing atomistic simulations (https://wiki.fysik.dtu.dk/ase/) | PySCF: collection of electronic structure programs (https://sunqm.github.io/pyscf/) | . . Editors and development environments . If Python code is not written interactively within the browser, as for example for larger projects, there are different editors and environments available to write Python code: . vi(m): text editor contained in most linux distributions | Kate (Linux): handy text editor, highlighting for many different languages | NotePad++ (Windows): https://notepad-plus-plus.org/ | Spyder: Integrated development environment (IDE), shipped with anaconda (https://www.spyder-ide.org/) | PyCharm: Powerful IDE, particular for python (http://www.jetbrains.com/pycharm) | PyDev: Plugin for Eclipse IDE, i.e. auch für Java &amp; C/C++ (https://www.pydev.org/download.html) | . . Python - Advanced topics &amp; concepts . A lot of interesting and useful stuff has been left out in this short introduction due to the sake of brevity. There is a lot more to Python, here a just a few keywords to look up: . Exceptions | List comprehensions | Lambda expressions | Logging | Multiprocessing &amp; multithreading | JIT compiler (http://numba.pydata.org/) | . Python tutorials: . Google Python introduction (https://developers.google.com/edu/python/) | Scientific Python introduction (https://scipy-lectures.org/intro/) | .",
            "url": "https://chloschen.github.io/fastpages/2020/02/28/python_introduction_for_chemists.html",
            "relUrl": "/2020/02/28/python_introduction_for_chemists.html",
            "date": " • Feb 28, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Building a Simple Molecular Force Field with Python",
            "content": "This jupyter-notebook contains some commented code showing how to build a simple molecular forcefield with Python using the libraries numpy and scipy. It is hosted on the google colab platform and only a web browser is needed to run it. . Force Field are used to determine molecular structures and their respective (relative) energies. They are used in very different settings, ranging from drug development to materials research. . Usually empirical potential energy functions are used that map the atomic coordinates of a specifc configuration for a molecular, cluster or crystal $ textbf{X}$ to an scalar energy value $E$. $ textbf{X}$ just contains the (e.g. cartesian) coordinates of all the atoms in vector or matrix form. As the atomic positions are changed so changes the total energy. . $E = f( textbf{X})$ . Variations of the atomic coordinates may then be carried out in order to find a (local) minimum of the energy, or more exact of the so-called potential energy surface (PES). If the gradient of the energy function is given, the efficiency of the optimization process can be significantly improved. Analytical gradients are functions that map the coordinates to a vector field giving the direction of the strongest rate of function value change at the point $ textbf{X}$. . Hence, energy and gradient evaluations are typical made for a given atomic configuration, the coordinates are updated with this information from the gradients, and a new configuration $ textbf{X}&#39;$ is obtained. This process is iterated until the energy or the gradient does not change anymore with respect to a given threshold. . To further characterize those states, 2nd order derivatives of the PES are also sometimes computed. . . Optimizing Lennard-Jones Cluster . In order to construct our own little Force Field we deal with a very simple model system. Lennard-Jones clusters are atomic ensembles which are held together only by comparatively weak Van der Waals (VdW) Forces. No strong bonds are involved such as covalent bonds or hydrogen bonds, which typically define real molecules. However, the lack of directed bonds renders this system somewhat easier to treat. The VdW forces are experienced by all atoms and only depend on the interatomic distance: . $E = 4 epsilon sum_{i&lt;j} bigg[ bigg( frac{ sigma}{r_{ij}} bigg)^{12}- bigg( frac{ sigma}{r_{ij}} bigg)^{6} bigg]$ . Coding . First we import the necessary libraries. In particular numpy (http://www.numpy.org/) for linear algebra and scipy (https://www.scipy.org/) for some handy functions such as different optimizers. Its always a good idea not to re-invent the wheel... . import numpy as np from io import StringIO from scipy.optimize import minimize from scipy.optimize import basinhopping . Let us define the computation of the energy in a separate function. Here its useful to introduce the concept of the distance matrix, which is a $n_{atoms} times n_{atoms}$ matrix containing all the possible distances between the atoms of the system. Effectively, we compute only the upper triangular part of the distance matrix, as only unique distances are needed. . def calc_energy(coords,epsilon=1.0,sigma=1.0): #reshape coordinates to original 2D array tmpv = coords.reshape((natoms,3)) E=0.0 for i in range(natoms): for j in range(i+1,natoms): distv = tmpv[i] - tmpv[j] d = np.linalg.norm(distv) E += ((sigma/d)**12-(sigma/d)**6) E = 4*epsilon*E return(E) . Defining the random seed for reproducibility. We want to get the same results for the same input in case we use a stochastic process. . np.random.seed(42) . Let us parameterize the size of the system, so we can change it later on. Be careful not to enter too large integers here, computations may become quite costly. . natoms = 5 . Generating some random arrays via numpy, representing the initial atomic coordinates. Those will be far away from the minimum geometry, but we have to start somewhere. In this case we use a $n_{atoms} times 3$ matrix, containing in each row the x,y,z coordinates of an atom. For later use, we then reshape the coordinates into a 1D vector, because the scipy minimize function expects this shape. . coords = np.random.random((natoms,3)) coords = coords.reshape((natoms*3,)) coords . array([0.03438852, 0.9093204 , 0.25877998, 0.66252228, 0.31171108, 0.52006802, 0.54671028, 0.18485446, 0.96958463, 0.77513282, 0.93949894, 0.89482735, 0.59789998, 0.92187424, 0.0884925 ]) . Lets call and test the energy function, which we have defined earlier. It should give a rather large value, due to the randomness of the coordinates used as initial input. . Energies and Structure Optimisation . calc_energy(coords) . 28134.0478850889 . Now lets minimze the energy via the internal scipy minimize function. It containts a lot of different varations of minimizers, one is the Nealder-Mead simplex method (by the way, not to be confused with the &quot;simplex&quot; method used in linear programming). The Nealder-Mead simplex does not need any gradients and hence is quite useful if no gradients are available. For better performance we will have to implement gradients later on. . res = minimize(calc_energy, x0=coords, method=&#39;Nelder-Mead&#39;, tol=1e-6) print(&quot;Energy: %16.6f after %d function evaluations using the simplex optimizer.&quot;%(res.fun,res.nfev)) coords_opt = res.x.reshape((natoms,3)) . Energy: -9.103852 after 2323 function evaluations using the simplex optimizer. . Ok lets try another minimizer, the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. . res = minimize(calc_energy, x0=coords, method=&#39;BFGS&#39;, tol=1e-6) print(&quot;Energy: %16.6f after %d function evaluations using Broyden-Fletcher-Goldfarb-Shanno algorithm.&quot;%(res.fun,res.nfev)) coords_opt = res.x.reshape((natoms,3)) . Energy: -9.103852 after 3802 function evaluations using Broyden-Fletcher-Goldfarb-Shanno algorithm. . Global optimisation . We just performed a local optimisation and hence it is possible that we missed the energetically lowest structure. . A global optimisation algorithm is ussually applied in order to to find the energetically lowest structure. Of course, we can never be 100% sure that we did not miss a lower energy structure with our search. . However, for this kind of small clusters however the possibilities are limited and we should have an energy of E=-6.0000 for 4 atom and E=-9.103 852 for 5 atoms. The difference between a normal optimisation and a global one will be much more significant for larger atom numbers. But be careful, computation will also like increase. . For pre-computed results on larger systems and on details of the basin-hopping algorithm have a look at: . D. J. Wales and J. P. K. Doye The Journal of Physical Chemistry A 1997 101 (28), 5111-5116. (http://www-wales.ch.cam.ac.uk/pdf/JPCA.101.5111.1997.pdf) . res = basinhopping(calc_energy, x0=coords_opt,niter=100,T=1.0, stepsize=0.5) print(&quot;Energy: %16.6f after %d iterations.&quot;%(res.fun,res.nfev)) . Energy: -9.103852 after 234060 iterations. . Visualization . %matplotlib inline import matplotlib.pyplot as plt from mpl_toolkits import mplot3d . Now some visualization to inspect the results. . ax = plt.axes(projection=&#39;3d&#39;) ax.scatter(coords_opt[:,0], coords_opt[:,1], coords_opt[:,2], c=&#39;blue&#39;, linewidth=2.0); ax.set_xlabel(&#39;X&#39;) ax.set_ylabel(&#39;Y&#39;) ax.set_zlabel(&#39;Z&#39;) limits = (-3.0,3.0) ax.set_xlim(limits) ax.set_ylim(limits) ax.set_zlim(limits) . (-3.0, 3.0) . Gradients . Now lets implement a gradient function here to improve optimization performance. . def calc_gradient(coords,epsilon=1.0,sigma=1.0): #reshape coordinates to original 2D array tmpv = coords.reshape((natoms,3)) E=0.0 grad = np.zeros(natoms*3) for i in range(natoms): for j in range(i+1,natoms): distv = tmpv[i] - tmpv[j] d = np.linalg.norm(distv) E += ((sigma/d)**12-(sigma/d)**6) grad_ = -12 * (d/sigma)**(-13) + 6* (d/sigma)**(-7) grad[i] = grad[i] + grad_ grad[j] = grad[j] - grad_ E = 4*epsilon*E grad = 4*epsilon*grad grad = grad.reshape((natoms*3,)) return(grad) . For optimization we use the BFGS algorithm again, but this time with analytical gradient. . res = minimize(calc_energy, x0=coords_opt, method=&#39;BFGS&#39;, jac=calc_gradient, tol=1e-6) print(&quot;Energy: %16.6f after %d function evaluations using gradient info.&quot;%(res.fun,res.nfev)) . Energy: -9.103852 after 98 function evaluations using gradient info. . For a global optimzation we need a different strategy to ensure that we do not land in a local minimum. To use the scipy basin hopin algorithm we to restructure the energy and the gradient function somewhat: . def calc_energy_with_gradient(coords, epsilon=1.0,sigma=1.0): E = calc_energy(coords,epsilon,sigma) grad = calc_gradient(coords,epsilon,sigma) return(E,grad) . minimizer_kwargs = {&quot;method&quot;:&quot;L-BFGS-B&quot;, &quot;jac&quot;:True} res = basinhopping(calc_energy_with_gradient, x0=coords_opt,niter=1000,T=5.0, stepsize=1,minimizer_kwargs=minimizer_kwargs) print(&quot;Energy: %16.6f after %d function evaluations.&quot;%(res.fun,res.nfev)) . Energy: -9.103852 after 5387 function evaluations. . Outlook: More Complex Force Fields . Usually, molecular Force Fields contain also directed interactions such as covalent or hydrogen bonds, in addition to VdW interactions. . They very much resemble a spring and beads model where the atoms in a molecule are held together by a spring. The atomic connections i.e. covalent bonds between atoms have to be defined beforehand. Each bond is modelled in first order by a spring, which exerts a force on the atoms which increases linear with the distance from the equilibrium bond length. Hence, each characteristic bond (C-C single bond, C=C double bond, O-H bond etc.) can be represented by a spring constant. . Due to the fact that all bonds are determined beforehand, no bonds can be made or be broken in typical Force Fields, in fact no real chemistry can take place, as opposed to quantum chemistry. . In addition to those covalent bond terms, angle terms, dihedral terms, Van der Waals terms and some special terms are sometimes added to the overall energy function. The terms can be divided in bonded (e.g valence) terms $E_{val}$ and non-bonded terms $E_{nb}$ (see also J. Phys. Chem, Vol. 94, No. 26, 1990): . $E = E_{val}+E_{nb}$ . The valence interaction typically consist out of bond stretch ($E_{B}$, two-body), bond-angle bend ($E_{A}$, three body) and dihedral angle torsion ($E_{T}$, four body), and inversion terms ($E_I$, four body). . $E_{val}=E_{B}+E_{A}+E_{T}+E_{I}$ . The non-bonded interactions can may consist out of van der Waals or dispersion ($E_{vdW}$), electrostatic ($E_Q$) and explicit hydrogen bonding terms ($E_{hb}$): . $E_{nb}=E_{vdW}+E_{Q}+E_{hb}$ . The global optimisation of this kind of energy function corresponds to a conformer search, where the global energy minimum represents the most stable molecular conformation. . Molecular Force Field have their drawbacks such as their sometimes weak overall accuracy and lack of generality. But their are magnitudes faster than typical quantum chemical methods and are still in whitespread use. . The algorithms to optimize their structure are the same as for the more sophisticated quantum chemical methods. .",
            "url": "https://chloschen.github.io/fastpages/2020/02/28/forcefields_python.html",
            "relUrl": "/2020/02/28/forcefields_python.html",
            "date": " • Feb 28, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Besides other things, I am interested in machine &amp; deep learning and its overlap with &amp; applications to natural sciences, computational chemistry in particular. I have more than 15 years experience with various computational chemistry and cheminformatics methods and projects and applying those skills to real world problems. Contributions to more than 30 peer-review scientific publications, many as main author, also author and co-author on several patent grants. Kaggle Master. All opinions are my own. .",
          "url": "https://chloschen.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://chloschen.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}